{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyrus723/my-first-binder/blob/main/LDA_Kochmar2022_NLP_book_CH10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code has two parts: the first one is from scikit learn and the second one is from the book by Kochmar 2022."
      ],
      "metadata": {
        "id": "S_fzHXiCNx2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The first code: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py"
      ],
      "metadata": {
        "id": "2FHeLtzw_RKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
        "#         Lars Buitinck\n",
        "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "from time import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation, MiniBatchNMF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 10\n",
        "n_top_words = 20\n",
        "batch_size = 128\n",
        "init = \"nndsvda\"\n",
        "\n",
        "\n",
        "def plot_top_words(model, feature_names, n_top_words, title):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
        "    axes = axes.flatten()\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_features_ind = topic.argsort()[-n_top_words:]\n",
        "        top_features = feature_names[top_features_ind]\n",
        "        weights = topic[top_features_ind]\n",
        "\n",
        "        ax = axes[topic_idx]\n",
        "        ax.barh(top_features, weights, height=0.7)\n",
        "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
        "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
        "        for i in \"top right left\".split():\n",
        "            ax.spines[i].set_visible(False)\n",
        "        fig.suptitle(title, fontsize=40)\n",
        "\n",
        "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
        "# to filter out useless terms early on: the posts are stripped of headers,\n",
        "# footers and quoted replies, and common English words, words occurring in\n",
        "# only one document or in at least 95% of the documents are removed.\n",
        "\n",
        "print(\"Loading dataset...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AYkXYW_-5v-",
        "outputId": "eeb2b49b-c029-41d6-f169-4376c9640262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time()\n",
        "data, _ = fetch_20newsgroups(\n",
        "    shuffle=True,\n",
        "    random_state=1,\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    return_X_y=True,\n",
        ")\n",
        "data_samples = data[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print(len(data_samples))\n",
        "data_samples[1999]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "8rp03yaEOE3h",
        "outputId": "418919d6-0f5f-4b59-f870-18e66be34459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 3.208s.\n",
            "2000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\nNeither did he!\\n\\n\\nOverall?  How do you figure?\\n\\n\\nSo far my radio hasn't exploded from not being tuned to 660...\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tf-idf features for NMF.\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
        ")\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "type(tfidf)\n",
        "tfidf.shape\n",
        "print(tfidf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "EY-eomL1OUrn",
        "outputId": "e17b5af7-013e-49d1-9a23-3a755bf2b586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting tf-idf features for NMF...\n",
            "done in 1.101s.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csr.csr_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/scipy/sparse/_csr.py</a>Compressed Sparse Row matrix\n",
              "\n",
              "This can be instantiated in several ways:\n",
              "    csr_array(D)\n",
              "        with a dense matrix or rank-2 ndarray D\n",
              "\n",
              "    csr_array(S)\n",
              "        with another sparse matrix S (equivalent to S.tocsr())\n",
              "\n",
              "    csr_array((M, N), [dtype])\n",
              "        to construct an empty matrix with shape (M, N)\n",
              "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
              "\n",
              "    csr_array((data, (row_ind, col_ind)), [shape=(M, N)])\n",
              "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
              "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
              "\n",
              "    csr_array((data, indices, indptr), [shape=(M, N)])\n",
              "        is the standard CSR representation where the column indices for\n",
              "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
              "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
              "        If the shape parameter is not supplied, the matrix dimensions\n",
              "        are inferred from the index arrays.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "dtype : dtype\n",
              "    Data type of the matrix\n",
              "shape : 2-tuple\n",
              "    Shape of the matrix\n",
              "ndim : int\n",
              "    Number of dimensions (this is always 2)\n",
              "nnz\n",
              "    Number of stored values, including explicit zeros\n",
              "data\n",
              "    CSR format data array of the matrix\n",
              "indices\n",
              "    CSR format index array of the matrix\n",
              "indptr\n",
              "    CSR format index pointer array of the matrix\n",
              "has_sorted_indices\n",
              "    Whether indices are sorted\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              "Sparse matrices can be used in arithmetic operations: they support\n",
              "addition, subtraction, multiplication, division, and matrix power.\n",
              "\n",
              "Advantages of the CSR format\n",
              "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
              "  - efficient row slicing\n",
              "  - fast matrix vector products\n",
              "\n",
              "Disadvantages of the CSR format\n",
              "  - slow column slicing operations (consider CSC)\n",
              "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
              "\n",
              "Canonical Format\n",
              "    - Within each row, indices are sorted by column.\n",
              "    - There are no duplicate entries.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from scipy.sparse import csr_array\n",
              "&gt;&gt;&gt; csr_array((3, 4), dtype=np.int8).toarray()\n",
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]], dtype=int8)\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 0, 1, 2, 2, 2])\n",
              "&gt;&gt;&gt; col = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_array((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
              "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_array((data, indices, indptr), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "Duplicate entries are summed together:\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 1, 2, 0])\n",
              "&gt;&gt;&gt; col = np.array([0, 1, 1, 0])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 4, 8])\n",
              "&gt;&gt;&gt; csr_array((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[9, 0, 0],\n",
              "       [0, 2, 0],\n",
              "       [0, 4, 0]])\n",
              "\n",
              "As an example of how to construct a CSR matrix incrementally,\n",
              "the following snippet builds a term-document matrix from texts:\n",
              "\n",
              "&gt;&gt;&gt; docs = [[&quot;hello&quot;, &quot;world&quot;, &quot;hello&quot;], [&quot;goodbye&quot;, &quot;cruel&quot;, &quot;world&quot;]]\n",
              "&gt;&gt;&gt; indptr = [0]\n",
              "&gt;&gt;&gt; indices = []\n",
              "&gt;&gt;&gt; data = []\n",
              "&gt;&gt;&gt; vocabulary = {}\n",
              "&gt;&gt;&gt; for d in docs:\n",
              "...     for term in d:\n",
              "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
              "...         indices.append(index)\n",
              "...         data.append(1)\n",
              "...     indptr.append(len(indices))\n",
              "...\n",
              "&gt;&gt;&gt; csr_array((data, indices, indptr), dtype=int).toarray()\n",
              "array([[2, 1, 0, 0],\n",
              "       [0, 1, 1, 1]])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 370);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 708)\t0.12621877625178227\n",
            "  (0, 410)\t0.11650651629173196\n",
            "  (0, 493)\t0.1631127602376565\n",
            "  (0, 548)\t0.11873384536901997\n",
            "  (0, 130)\t0.13595955391213657\n",
            "  (0, 567)\t0.13595955391213657\n",
            "  (0, 412)\t0.12831668397369733\n",
            "  (0, 750)\t0.15376128408643466\n",
            "  (0, 841)\t0.18564440175793037\n",
            "  (0, 206)\t0.15810189392327795\n",
            "  (0, 764)\t0.1640284908630232\n",
            "  (0, 748)\t0.13595955391213657\n",
            "  (0, 904)\t0.08983671288492111\n",
            "  (0, 923)\t0.11966934266418663\n",
            "  (0, 527)\t0.1690393571774018\n",
            "  (0, 432)\t0.13369075280946802\n",
            "  (0, 988)\t0.12740095334833063\n",
            "  (0, 488)\t0.3750048191807266\n",
            "  (0, 717)\t0.17767638066823058\n",
            "  (0, 587)\t0.6454209423982519\n",
            "  (0, 862)\t0.1551447391479567\n",
            "  (0, 286)\t0.11115911128919416\n",
            "  (0, 867)\t0.15810189392327795\n",
            "  (0, 881)\t0.11227372176926384\n",
            "  (1, 381)\t0.20157910011124136\n",
            "  :\t:\n",
            "  (1998, 504)\t0.04875543232365812\n",
            "  (1998, 991)\t0.053978162418983656\n",
            "  (1998, 566)\t0.03637572081429063\n",
            "  (1998, 611)\t0.05504978412016225\n",
            "  (1998, 171)\t0.047384737904817335\n",
            "  (1998, 414)\t0.08876861152823663\n",
            "  (1998, 268)\t0.23575826480007847\n",
            "  (1998, 491)\t0.1114848475886964\n",
            "  (1998, 271)\t0.05622767285588837\n",
            "  (1998, 907)\t0.06818500433590943\n",
            "  (1998, 710)\t0.05998220148907317\n",
            "  (1998, 998)\t0.04605022195294345\n",
            "  (1998, 173)\t0.10248793661244614\n",
            "  (1998, 122)\t0.05810140044184461\n",
            "  (1998, 984)\t0.0397488592737133\n",
            "  (1998, 533)\t0.05951387738098097\n",
            "  (1998, 306)\t0.030847223209189208\n",
            "  (1998, 540)\t0.12852849537452227\n",
            "  (1998, 130)\t0.04971790762820881\n",
            "  (1998, 750)\t0.05622767285588837\n",
            "  (1998, 286)\t0.04064884201283483\n",
            "  (1999, 738)\t0.5707845186348437\n",
            "  (1999, 366)\t0.56500361648845\n",
            "  (1999, 356)\t0.44578463121221495\n",
            "  (1999, 286)\t0.3952872489933768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tf (raw term count) features for LDA.\n",
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(\n",
        "    max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
        ")\n",
        "t0 = time()\n",
        "tf = tf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print()\n",
        "\n",
        "# Fit the NMF model\n",
        "print(\n",
        "    \"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "    \"n_samples=%d and n_features=%d...\" % (n_samples, n_features)\n",
        ")\n",
        "t0 = time()\n",
        "nmf = NMF(\n",
        "    n_components=n_components,\n",
        "    random_state=1,\n",
        "    init=init,\n",
        "    beta_loss=\"frobenius\",\n",
        "    alpha_W=0.00005,\n",
        "    alpha_H=0.00005,\n",
        "    l1_ratio=1,\n",
        ").fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(\n",
        "    nmf, tfidf_feature_names, n_top_words, \"Topics in NMF model (Frobenius norm)\"\n",
        ")\n",
        "\n",
        "# Fit the NMF model\n",
        "print(\n",
        "    \"\\n\" * 2,\n",
        "    \"Fitting the NMF model (generalized Kullback-Leibler \"\n",
        "    \"divergence) with tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "    % (n_samples, n_features),\n",
        ")\n",
        "t0 = time()\n",
        "nmf = NMF(\n",
        "    n_components=n_components,\n",
        "    random_state=1,\n",
        "    init=init,\n",
        "    beta_loss=\"kullback-leibler\",\n",
        "    solver=\"mu\",\n",
        "    max_iter=1000,\n",
        "    alpha_W=0.00005,\n",
        "    alpha_H=0.00005,\n",
        "    l1_ratio=0.5,\n",
        ").fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(\n",
        "    nmf,\n",
        "    tfidf_feature_names,\n",
        "    n_top_words,\n",
        "    \"Topics in NMF model (generalized Kullback-Leibler divergence)\",\n",
        ")\n",
        "\n",
        "# Fit the MiniBatchNMF model\n",
        "print(\n",
        "    \"\\n\" * 2,\n",
        "    \"Fitting the MiniBatchNMF model (Frobenius norm) with tf-idf \"\n",
        "    \"features, n_samples=%d and n_features=%d, batch_size=%d...\"\n",
        "    % (n_samples, n_features, batch_size),\n",
        ")\n",
        "t0 = time()\n",
        "mbnmf = MiniBatchNMF(\n",
        "    n_components=n_components,\n",
        "    random_state=1,\n",
        "    batch_size=batch_size,\n",
        "    init=init,\n",
        "    beta_loss=\"frobenius\",\n",
        "    alpha_W=0.00005,\n",
        "    alpha_H=0.00005,\n",
        "    l1_ratio=0.5,\n",
        ").fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(\n",
        "    mbnmf,\n",
        "    tfidf_feature_names,\n",
        "    n_top_words,\n",
        "    \"Topics in MiniBatchNMF model (Frobenius norm)\",\n",
        ")\n",
        "\n",
        "# Fit the MiniBatchNMF model\n",
        "print(\n",
        "    \"\\n\" * 2,\n",
        "    \"Fitting the MiniBatchNMF model (generalized Kullback-Leibler \"\n",
        "    \"divergence) with tf-idf features, n_samples=%d and n_features=%d, \"\n",
        "    \"batch_size=%d...\" % (n_samples, n_features, batch_size),\n",
        ")\n",
        "t0 = time()\n",
        "mbnmf = MiniBatchNMF(\n",
        "    n_components=n_components,\n",
        "    random_state=1,\n",
        "    batch_size=batch_size,\n",
        "    init=init,\n",
        "    beta_loss=\"kullback-leibler\",\n",
        "    alpha_W=0.00005,\n",
        "    alpha_H=0.00005,\n",
        "    l1_ratio=0.5,\n",
        ").fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(\n",
        "    mbnmf,\n",
        "    tfidf_feature_names,\n",
        "    n_top_words,\n",
        "    \"Topics in MiniBatchNMF model (generalized Kullback-Leibler divergence)\",\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"\\n\" * 2,\n",
        "    \"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
        "    % (n_samples, n_features),\n",
        ")\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=n_components,\n",
        "    max_iter=5,\n",
        "    learning_method=\"online\",\n",
        "    learning_offset=50.0,\n",
        "    random_state=0,\n",
        ")\n",
        "t0 = time()\n",
        "lda.fit(tf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(lda, tf_feature_names, n_top_words, \"Topics in LDA model\")"
      ],
      "metadata": {
        "id": "y5kCqfaZPJlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH7Sxc727Dsa"
      },
      "source": [
        "# Source: https://github.com/ekochmar/Getting-Started-with-NLP/blob/master/Chapter10.ipynb Chapter 10: LDA for Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf5yraXr7Dsd"
      },
      "source": [
        "## Load Newsgroups data\n",
        "\n",
        "As before, let's consider a specific set of categories:\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset\n",
        "\n",
        "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.\n",
        "\n",
        "This module contains two loaders. The first one, sklearn.datasets.fetch_20newsgroups, returns a list of the raw texts that can be fed to text feature extractors such as CountVectorizer with custom parameters so as to extract feature vectors. The second one, sklearn.datasets.fetch_20newsgroups_vectorized, returns ready-to-use features, i.e., it is not necessary to use a feature extractor.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwopWBE79MmQ",
        "outputId": "35c61f45-61b9-4e31-f0da-5af78dc2397b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p6sGJzp7Dse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a232a54-f058-4f01-d123-c61eef350b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "def load_dataset(sset, cats):\n",
        "    if cats==[]:\n",
        "        newsgroups_dset = fetch_20newsgroups(subset=sset,\n",
        "                          remove=('headers', 'footers', 'quotes'),\n",
        "                          shuffle=True)\n",
        "    else:\n",
        "        newsgroups_dset = fetch_20newsgroups(subset=sset, categories=cats,\n",
        "                          remove=('headers', 'footers', 'quotes'),\n",
        "                          shuffle=True)\n",
        "    return newsgroups_dset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXB2ImNP7Dsf",
        "outputId": "d73b19a1-768f-4d25-8b96-c0ef5e004035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9850\n"
          ]
        }
      ],
      "source": [
        "categories = [\"comp.windows.x\", \"misc.forsale\", \"rec.autos\", \"rec.motorcycles\", \"rec.sport.baseball\"]\n",
        "categories += [\"rec.sport.hockey\", \"sci.crypt\", \"sci.med\", \"sci.space\", \"talk.politics.mideast\"]\n",
        "\n",
        "newsgroups_all = load_dataset('all', categories)\n",
        "print(len(newsgroups_all.data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_all.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qigi1mT893mf",
        "outputId": "6c4c2d41-297b-4f6f-ebbd-75e028f77e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boMhBphQ7Dsg"
      },
      "source": [
        "## Preprocess\n",
        "\n",
        "Convert word forms to stems to get concise representations for the documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EysSi8EE7Dsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35807f2-07a2-4a02-e0a5-70dde8a78699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stem(text):\n",
        "    return stemmer.stem(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E60KV4C97Dsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfc7825-4e74-4083-f4a3-a626e01aa192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS as stopwords\n",
        "\n",
        "#print(stopwords)\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text, min_len=4):\n",
        "        if token not in stopwords: #and len(token) > 3:\n",
        "            result.append(stem(token))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aak2xZFK7Dsh"
      },
      "source": [
        "Check how each document is represented. For example, look into the very first one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orjYOM_p7Dsh",
        "outputId": "c8081d70-aaf6-432a-977f-7bf816c245c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original document: \n",
            "Hi Xperts!\n",
            "\n",
            "How can I move the cursor with the keyboard (i.e. cursor keys), \n",
            "if no mouse is available?\n",
            "\n",
            "Any hints welcome.\n",
            "\n",
            "Thanks.\n",
            "\n",
            "\n",
            "Tokenized document: \n",
            "['Hi', 'Xperts', 'How', 'can', 'I', 'move', 'the', 'cursor', 'with', 'the', 'keyboard', 'i', 'e', 'cursor', 'keys', 'if', 'no', 'mouse', 'is', 'available', 'Any', 'hints', 'welcome', 'Thanks']\n",
            "\n",
            "\n",
            "Preprocessed document: \n",
            "['xpert', 'cursor', 'keyboard', 'cursor', 'key', 'mous', 'avail', 'hint', 'welcom', 'thank']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "doc_sample = newsgroups_all.data[0]\n",
        "print('Original document: ')\n",
        "print(doc_sample)\n",
        "\n",
        "print('\\n\\nTokenized document: ')\n",
        "words = []\n",
        "for token in gensim.utils.tokenize(doc_sample):\n",
        "    words.append(token)\n",
        "print(words)\n",
        "\n",
        "print('\\n\\nPreprocessed document: ')\n",
        "print(preprocess(doc_sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCIijFm7Dsi"
      },
      "source": [
        "How do the first 10 look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osvVgf0v7Dsi",
        "outputId": "80fb67f0-759c-4117-fe9c-6ce3a12cbab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\txpert, cursor, keyboard, cursor, key, mous, avail, hint, welcom, thank\n",
            "1\tobtain, copi, open, look, widget, obtain, need, order, copi, thank\n",
            "2\tright, signal, strong, live, west, philadelphia, perfect, sport, fan, dream\n",
            "3\tcanadian, thing, coach, boston, bruin, colorado, rocki, summari, post, gather\n",
            "4\theck, feel, like, time, includ, cafeteria, work, half, time, headach\n",
            "5\tdamn, right, late, climb, meet, morn, bother, right, foot, asleep\n",
            "6\tolympus, stylus, pocket, camera, smallest, class, includ, time, date, stamp\n",
            "7\tinclud, follow, chmos, clock, generat, driver, processor, chmos, eras, prom\n",
            "8\tchang, intel, discov, xclient, xload, longer, work, bomb, messag, error\n",
            "9\ttermin, like, power, server, run, window, manag, special, client, program\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, 10):\n",
        "    print(str(i) + \"\\t\" + \", \".join(preprocess(newsgroups_all.data[i])[:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEczJc0-7Dsi"
      },
      "source": [
        "Now let's represent each document as a dictionary of relevant words. Each word (*value* in the dictionary) has a unique identifier (*key*):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l0QbJo67Dsi",
        "outputId": "3f9811f2-2e57-4e32-f788-12e4092fc323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9850\n",
            "39350\n",
            "0 avail\n",
            "1 cursor\n",
            "2 hint\n",
            "3 key\n",
            "4 keyboard\n",
            "5 mous\n",
            "6 thank\n",
            "7 welcom\n",
            "8 xpert\n",
            "9 copi\n"
          ]
        }
      ],
      "source": [
        "processed_docs = []\n",
        "for i in range(0, len(newsgroups_all.data)):\n",
        "    processed_docs.append(preprocess(newsgroups_all.data[i]))\n",
        "\n",
        "print(len(processed_docs))\n",
        "\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "print(len(dictionary))\n",
        "\n",
        "index = 0\n",
        "for key, value in dictionary.iteritems():\n",
        "    print(key, value)\n",
        "    index += 1\n",
        "    if index > 9:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4x81BlW7Dsj"
      },
      "source": [
        "Put some contraints on the dictionary of terms: for instance, keep up to $100,000$ words that occur more frequently than $10$ times (`no_below`) and less frequently than in $50\\%$ of the documents (`no_above`). This should help you extract the most useful terms, while still keeping a reasonable number of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu7j2fAV7Dsj",
        "outputId": "fc5f931f-fe6d-48a1-e474-12c26e1be593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=100000)\n",
        "print(len(dictionary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2DiDMqp7Dsj"
      },
      "source": [
        "Let's see how a particular document is represented in this dictionary: for example, look into the very first post, or into the 100th:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90r1HUsV7Dsj",
        "outputId": "3f0b1504-9ba0-49b9-b743-7d0ebc59bec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[0]\n",
        "#bow_corpus[99]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGHKdL997Dsj"
      },
      "source": [
        "Let's decode what each index (key) in this dictionary points to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqsy9Ywn7Dsj",
        "outputId": "790da678-b0c2-4d92-fe6e-bc8435aa5bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key 0 =\"avail\":    occurrences=1\n",
            "Key 1 =\"cursor\":    occurrences=2\n",
            "Key 2 =\"hint\":    occurrences=1\n",
            "Key 3 =\"key\":    occurrences=1\n",
            "Key 4 =\"keyboard\":    occurrences=1\n",
            "Key 5 =\"mous\":    occurrences=1\n",
            "Key 6 =\"thank\":    occurrences=1\n",
            "Key 7 =\"welcom\":    occurrences=1\n",
            "Key 8 =\"xpert\":    occurrences=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "#bow_doc = bow_corpus[99]\n",
        "bow_doc = bow_corpus[0]\n",
        "\n",
        "for i in range(len(bow_doc)):\n",
        "    print(f\"Key {bow_doc[i][0]} =\\\"{dictionary[bow_doc[i][0]]}\\\":\\\n",
        "    occurrences={bow_doc[i][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWcrenAD7Dsk"
      },
      "source": [
        "## Train an LDA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6K7YVND7Dsk",
        "outputId": "d5f850f9-db9d-4a1e-b469-43a51587a73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.021*\"encrypt\" + 0.018*\"secur\" + 0.018*\"chip\" + 0.016*\"govern\" + 0.013*\"clipper\" + 0.012*\"public\" + 0.010*\"privaci\" + 0.010*\"key\" + 0.010*\"phone\" + 0.009*\"algorithm\"\n",
            "Topic: 1 \n",
            "Words: 0.017*\"appear\" + 0.014*\"copi\" + 0.013*\"cover\" + 0.013*\"star\" + 0.013*\"book\" + 0.011*\"penalti\" + 0.010*\"black\" + 0.009*\"comic\" + 0.008*\"blue\" + 0.008*\"green\"\n",
            "Topic: 2 \n",
            "Words: 0.031*\"window\" + 0.015*\"server\" + 0.012*\"program\" + 0.012*\"file\" + 0.012*\"applic\" + 0.012*\"display\" + 0.011*\"widget\" + 0.010*\"version\" + 0.010*\"motif\" + 0.010*\"support\"\n",
            "Topic: 3 \n",
            "Words: 0.015*\"space\" + 0.007*\"launch\" + 0.007*\"year\" + 0.007*\"medic\" + 0.006*\"patient\" + 0.006*\"orbit\" + 0.006*\"research\" + 0.006*\"diseas\" + 0.005*\"develop\" + 0.005*\"nasa\"\n",
            "Topic: 4 \n",
            "Words: 0.018*\"armenian\" + 0.011*\"peopl\" + 0.008*\"kill\" + 0.008*\"said\" + 0.007*\"turkish\" + 0.006*\"muslim\" + 0.006*\"jew\" + 0.006*\"govern\" + 0.005*\"state\" + 0.005*\"greek\"\n",
            "Topic: 5 \n",
            "Words: 0.024*\"price\" + 0.021*\"sale\" + 0.020*\"offer\" + 0.017*\"drive\" + 0.017*\"sell\" + 0.016*\"includ\" + 0.013*\"ship\" + 0.013*\"interest\" + 0.011*\"ask\" + 0.010*\"condit\"\n",
            "Topic: 6 \n",
            "Words: 0.018*\"mail\" + 0.016*\"list\" + 0.015*\"file\" + 0.015*\"inform\" + 0.013*\"send\" + 0.012*\"post\" + 0.012*\"avail\" + 0.010*\"request\" + 0.010*\"program\" + 0.009*\"includ\"\n",
            "Topic: 7 \n",
            "Words: 0.019*\"like\" + 0.016*\"know\" + 0.011*\"time\" + 0.011*\"look\" + 0.010*\"think\" + 0.008*\"want\" + 0.008*\"thing\" + 0.008*\"good\" + 0.007*\"go\" + 0.007*\"bike\"\n",
            "Topic: 8 \n",
            "Words: 0.033*\"game\" + 0.022*\"team\" + 0.017*\"play\" + 0.015*\"year\" + 0.013*\"player\" + 0.011*\"season\" + 0.008*\"hockey\" + 0.008*\"score\" + 0.007*\"leagu\" + 0.007*\"goal\"\n",
            "Topic: 9 \n",
            "Words: 0.013*\"peopl\" + 0.012*\"think\" + 0.011*\"like\" + 0.009*\"time\" + 0.009*\"right\" + 0.009*\"israel\" + 0.009*\"know\" + 0.006*\"reason\" + 0.006*\"point\" + 0.006*\"thing\"\n"
          ]
        }
      ],
      "source": [
        "# Create the dictionary\n",
        "id2word = dictionary\n",
        "\n",
        "# Create the corpus with word frequencies\n",
        "corpus = bow_corpus\n",
        "\n",
        "# Build the LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10,\n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=1000,\n",
        "                                           passes=10,\n",
        "                                           alpha='symmetric',\n",
        "                                           iterations=100,\n",
        "                                           per_word_topics=True)\n",
        "\n",
        "\n",
        "for index, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Topic: {index} \\nWords: {topic}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBheSrFS7Dsk"
      },
      "source": [
        "## Interpret the results\n",
        "\n",
        "What is the most representative topic in each document?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u18dKneK7Dsk",
        "outputId": "99fd90e8-b298-446c-af95-851100114ed4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ID  Main Topic  Contribution (%)  Keywords                                Snippet                                                                           \n",
            " 0   2           0.8268            window, server, program, file, applic\n",
            "  ['xpert', 'cursor', 'keyboard', 'cursor', 'key', 'mous', 'avail', 'hint']         \n",
            " 1   6           0.4741            mail, list, file, inform, send\n",
            "         ['obtain', 'copi', 'open', 'look', 'widget', 'obtain', 'need', 'order']           \n",
            " 2   7           0.4230            like, know, time, look, think\n",
            "          ['right', 'signal', 'strong', 'live', 'west', 'philadelphia', 'perfect', 'sport'] \n",
            " 3   8           0.4159            game, team, play, year, player\n",
            "         ['canadian', 'thing', 'coach', 'boston', 'bruin', 'colorado', 'rocki', 'summari'] \n",
            " 4   9           0.9039            peopl, think, like, time, right\n",
            "        ['heck', 'feel', 'like', 'time', 'includ', 'cafeteria', 'work', 'half']           \n",
            " 5   7           0.6291            like, know, time, look, think\n",
            "          ['damn', 'right', 'late', 'climb', 'meet', 'morn', 'bother', 'right']             \n",
            " 6   3           0.3485            space, launch, year, medic, patient\n",
            "    ['olympus', 'stylus', 'pocket', 'camera', 'smallest', 'class', 'includ', 'time']  \n",
            " 7   5           0.3799            price, sale, offer, drive, sell\n",
            "        ['includ', 'follow', 'chmos', 'clock', 'generat', 'driver', 'processor', 'chmos'] \n",
            " 8   2           0.7943            window, server, program, file, applic\n",
            "  ['chang', 'intel', 'discov', 'xclient', 'xload', 'longer', 'work', 'bomb']        \n",
            " 9   2           0.6383            window, server, program, file, applic\n",
            "  ['termin', 'like', 'power', 'server', 'run', 'window', 'manag', 'special']        \n"
          ]
        }
      ],
      "source": [
        "def analyse_topics(ldamodel, corpus, texts):\n",
        "    main_topic = {}\n",
        "    percentage = {}\n",
        "    keywords = {}\n",
        "    text_snippets = {}\n",
        "    # Get main topic in each document\n",
        "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "        #print(\"\\n\")\n",
        "        #print(topic_list)\n",
        "        #print(\"\\n\")\n",
        "        #for i in range(0, len(topic_list)):\n",
        "        #    print (topic_list[i])\n",
        "        topic = topic_list[0] if ldamodel.per_word_topics else topic_list\n",
        "        #print(topic)\n",
        "        topic = sorted(topic, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the main topic, contribution (%) and keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(topic):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp[:5]])\n",
        "                main_topic[i] = int(topic_num)\n",
        "                percentage[i] = round(prop_topic,4)\n",
        "                keywords[i] = topic_keywords\n",
        "                text_snippets[i] = texts[i][:8]\n",
        "            else:\n",
        "                break\n",
        "    return main_topic, percentage, keywords, text_snippets\n",
        "\n",
        "\n",
        "main_topic, percentage, keywords, text_snippets = analyse_topics(\n",
        "    lda_model, bow_corpus, processed_docs)\n",
        "\n",
        "indexes = []\n",
        "rows = []\n",
        "for i in range(0, 10):\n",
        "    indexes.append(i)\n",
        "rows.append(['ID', 'Main Topic', 'Contribution (%)', 'Keywords', 'Snippet'])\n",
        "\n",
        "for idx in indexes:\n",
        "    rows.append([str(idx), f\"{main_topic.get(idx)}\",\n",
        "                f\"{percentage.get(idx):.4f}\",\n",
        "                f\"{keywords.get(idx)}\\n\",\n",
        "                f\"{text_snippets.get(idx)}\"])\n",
        "\n",
        "columns = zip(*rows)\n",
        "column_widths = [max(len(item) for item in col) for col in columns]\n",
        "for row in rows:\n",
        "    print(''.join(' {:{width}} '.format(row[i], width=column_widths[i])\n",
        "                  for i in range(0, len(row))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMc5ux2t7Dsk"
      },
      "source": [
        "## Explore words and topics with pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUp8QHbvAwHn",
        "outputId": "ca8bf56a-ecc5-4809-f8ca-7d6717f60b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1KxmDhs7Dsk",
        "outputId": "bef78cc5-142d-4479-8b77-aa6232fe12f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "9     -0.071377 -0.158078       1        1  16.071927\n",
              "7      0.021286 -0.150129       2        1  15.558590\n",
              "4      0.043482 -0.124777       3        1  14.496566\n",
              "3     -0.061378  0.005043       4        1  12.560903\n",
              "8      0.209139 -0.183924       5        1   9.811112\n",
              "6     -0.159857  0.164965       6        1   9.367518\n",
              "2     -0.185643  0.098444       7        1   7.512238\n",
              "0     -0.170320 -0.041934       8        1   6.917601\n",
              "5      0.083449  0.192866       9        1   4.629165\n",
              "1      0.291219  0.197524      10        1   3.074380, topic_info=          Term         Freq        Total Category  logprob  loglift\n",
              "123       game  2208.000000  2208.000000  Default  30.0000  30.0000\n",
              "273     window  1629.000000  1629.000000  Default  29.0000  29.0000\n",
              "598   armenian  1712.000000  1712.000000  Default  28.0000  28.0000\n",
              "86        team  1451.000000  1451.000000  Default  27.0000  27.0000\n",
              "254       mail  1397.000000  1397.000000  Default  26.0000  26.0000\n",
              "...        ...          ...          ...      ...      ...      ...\n",
              "311       forc   152.259346   683.518669  Topic10  -4.8725   1.9804\n",
              "693      white    98.456731   321.460693  Topic10  -5.3085   2.2988\n",
              "468       issu   108.238154   724.231507  Topic10  -5.2138   1.5813\n",
              "130       left   100.041159   792.443258  Topic10  -5.2925   1.4125\n",
              "1087     earth    91.108224   416.682392  Topic10  -5.3860   1.9618\n",
              "\n",
              "[648 rows x 6 columns], token_table=      Topic      Freq     Term\n",
              "term                          \n",
              "1713      2  0.994027    accid\n",
              "97        1  0.591889   actual\n",
              "97        2  0.241280   actual\n",
              "97        4  0.002513   actual\n",
              "97        5  0.049010   actual\n",
              "...     ...       ...      ...\n",
              "156       6  0.034544     year\n",
              "156       8  0.002348     year\n",
              "156       9  0.040916     year\n",
              "2740      4  0.991196    yeast\n",
              "5438      1  0.990100  zionist\n",
              "\n",
              "[1523 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[10, 8, 5, 4, 9, 7, 3, 1, 6, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el6781384881889116801062507508\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el6781384881889116801062507508_data = {\"mdsDat\": {\"x\": [-0.07137682955319377, 0.02128614584144924, 0.043481599255303975, -0.06137789447956354, 0.2091388175718718, -0.15985682422385328, -0.18564346524250572, -0.17031953681215894, 0.08344927916665491, 0.2912187084759953], \"y\": [-0.1580778110103607, -0.15012946801092658, -0.12477660132351973, 0.005042601942306186, -0.1839236880795499, 0.16496543976379272, 0.09844380430955345, -0.04193409792927276, 0.19286551148102904, 0.1975243088569481], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [16.07192684913915, 15.558590014352362, 14.49656622986682, 12.56090261910114, 9.811112162508843, 9.367517935776254, 7.512238025519145, 6.9176010554466565, 4.629164942935013, 3.0743801653546248]}, \"tinfo\": {\"Term\": [\"game\", \"window\", \"armenian\", \"team\", \"mail\", \"file\", \"encrypt\", \"govern\", \"play\", \"includ\", \"price\", \"secur\", \"chip\", \"space\", \"think\", \"program\", \"peopl\", \"drive\", \"inform\", \"sale\", \"player\", \"offer\", \"server\", \"list\", \"like\", \"season\", \"send\", \"know\", \"israel\", \"post\", \"israel\", \"isra\", \"argument\", \"echo\", \"hitter\", \"cell\", \"morri\", \"vote\", \"printf\", \"reveal\", \"prison\", \"impli\", \"lebanon\", \"lean\", \"lebanes\", \"tommi\", \"zionist\", \"quack\", \"vaccin\", \"silicon\", \"asid\", \"eat\", \"counterst\", \"throttl\", \"phrase\", \"void\", \"suspens\", \"photographi\", \"protein\", \"invent\", \"palestinian\", \"realiti\", \"certain\", \"opinion\", \"ignor\", \"agre\", \"situat\", \"reason\", \"claim\", \"mean\", \"think\", \"evid\", \"true\", \"believ\", \"fact\", \"peopl\", \"right\", \"actual\", \"word\", \"clear\", \"read\", \"question\", \"point\", \"case\", \"differ\", \"like\", \"time\", \"post\", \"know\", \"thing\", \"state\", \"want\", \"make\", \"good\", \"sure\", \"idea\", \"problem\", \"person\", \"bike\", \"ride\", \"car\", \"tire\", \"brake\", \"wheel\", \"detector\", \"ford\", \"steer\", \"honda\", \"helmet\", \"batteri\", \"accid\", \"cellular\", \"nois\", \"toyota\", \"stereo\", \"cage\", \"shit\", \"jerusalem\", \"tune\", \"depress\", \"ensur\", \"valv\", \"automobil\", \"smooth\", \"coat\", \"cassett\", \"plastic\", \"alarm\", \"rear\", \"gear\", \"motorcycl\", \"passeng\", \"lock\", \"insur\", \"speed\", \"dealer\", \"engin\", \"heard\", \"go\", \"turn\", \"mile\", \"know\", \"like\", \"went\", \"look\", \"seat\", \"littl\", \"rememb\", \"told\", \"thing\", \"stuff\", \"door\", \"start\", \"think\", \"come\", \"time\", \"want\", \"mayb\", \"good\", \"happen\", \"work\", \"need\", \"get\", \"tell\", \"problem\", \"say\", \"said\", \"year\", \"right\", \"peopl\", \"armenian\", \"turkish\", \"muslim\", \"greek\", \"villag\", \"turk\", \"armenia\", \"genocid\", \"soldier\", \"turkey\", \"azerbaijani\", \"azerbaijan\", \"court\", \"nazi\", \"murder\", \"azeri\", \"ottoman\", \"neighbor\", \"greec\", \"istanbul\", \"serdar\", \"argic\", \"tartar\", \"troop\", \"terror\", \"shout\", \"baku\", \"wound\", \"sumgait\", \"london\", \"jew\", \"massacr\", \"islam\", \"kill\", \"russian\", \"armi\", \"popul\", \"jewish\", \"children\", \"arm\", \"histori\", \"soviet\", \"said\", \"women\", \"peopl\", \"govern\", \"nation\", \"live\", \"arab\", \"state\", \"report\", \"world\", \"year\", \"univers\", \"attack\", \"launch\", \"patient\", \"orbit\", \"diseas\", \"mission\", \"satellit\", \"infect\", \"shuttl\", \"cancer\", \"aid\", \"clinic\", \"medicin\", \"spacecraft\", \"lunar\", \"newslett\", \"candida\", \"diet\", \"belt\", \"physician\", \"vitamin\", \"mar\", \"therapi\", \"temperatur\", \"saturn\", \"yeast\", \"chronic\", \"symptom\", \"immun\", \"syndrom\", \"antibiot\", \"health\", \"probe\", \"medic\", \"nasa\", \"space\", \"scienc\", \"treatment\", \"studi\", \"research\", \"earth\", \"center\", \"drug\", \"develop\", \"test\", \"increas\", \"rocket\", \"effect\", \"project\", \"report\", \"april\", \"caus\", \"year\", \"high\", \"program\", \"provid\", \"inform\", \"season\", \"hockey\", \"score\", \"basebal\", \"pitch\", \"leaf\", \"win\", \"detroit\", \"chicago\", \"fan\", \"pitcher\", \"pittsburgh\", \"sabr\", \"philadelphia\", \"montreal\", \"buffalo\", \"minnesota\", \"bruin\", \"coach\", \"devil\", \"calgari\", \"loui\", \"pen\", \"puck\", \"jose\", \"bat\", \"inning\", \"goali\", \"shark\", \"winnipeg\", \"team\", \"playoff\", \"player\", \"leagu\", \"game\", \"flyer\", \"play\", \"toronto\", \"ranger\", \"boston\", \"goal\", \"king\", \"stat\", \"period\", \"defens\", \"divis\", \"shot\", \"year\", \"seri\", \"lost\", \"point\", \"second\", \"good\", \"better\", \"time\", \"think\", \"anonym\", \"entri\", \"internet\", \"string\", \"byte\", \"cipher\", \"openwindow\", \"readm\", \"mathemat\", \"subscrib\", \"macintosh\", \"filenam\", \"pixmap\", \"den\", \"cryptolog\", \"uuencod\", \"recipi\", \"keyword\", \"olwm\", \"donat\", \"icon\", \"cryptanalysi\", \"hellman\", \"subscript\", \"tutori\", \"prog\", \"listserv\", \"dorothi\", \"austin\", \"consortium\", \"bitnet\", \"stream\", \"info\", \"usenet\", \"request\", \"output\", \"configur\", \"send\", \"address\", \"mail\", \"list\", \"archiv\", \"site\", \"email\", \"distribut\", \"section\", \"file\", \"inform\", \"avail\", \"network\", \"newsgroup\", \"comput\", \"post\", \"messag\", \"user\", \"softwar\", \"program\", \"sourc\", \"includ\", \"group\", \"news\", \"number\", \"line\", \"thank\", \"subject\", \"display\", \"widget\", \"motif\", \"font\", \"xterm\", \"contrib\", \"default\", \"xfree\", \"null\", \"xview\", \"toolkit\", \"xlib\", \"pixel\", \"suno\", \"microsoft\", \"colormap\", \"cursor\", \"pointer\", \"sparc\", \"mustang\", \"exit\", \"pars\", \"gaza\", \"login\", \"argv\", \"linux\", \"bitmap\", \"menu\", \"arg\", \"makefil\", \"mous\", \"client\", \"window\", \"screen\", \"server\", \"applic\", \"button\", \"color\", \"patch\", \"interfac\", \"version\", \"error\", \"resourc\", \"graphic\", \"defin\", \"compil\", \"function\", \"support\", \"program\", \"file\", \"run\", \"manag\", \"code\", \"includ\", \"problem\", \"work\", \"export\", \"event\", \"user\", \"look\", \"help\", \"like\", \"encrypt\", \"chip\", \"privaci\", \"escrow\", \"wiretap\", \"cryptographi\", \"crypto\", \"scheme\", \"decrypt\", \"ripem\", \"amend\", \"patent\", \"crypt\", \"plaintext\", \"imak\", \"surveil\", \"classifi\", \"intellect\", \"cryptograph\", \"cadr\", \"chastiti\", \"ciphertext\", \"netcom\", \"amour\", \"clipper\", \"algorithm\", \"preview\", \"laptop\", \"aura\", \"hacker\", \"secur\", \"enforc\", \"privat\", \"key\", \"agenc\", \"clinton\", \"devic\", \"secret\", \"phone\", \"trust\", \"govern\", \"communic\", \"technolog\", \"public\", \"block\", \"legal\", \"propos\", \"protect\", \"messag\", \"data\", \"administr\", \"number\", \"need\", \"develop\", \"inform\", \"sale\", \"espn\", \"printer\", \"clemen\", \"uucp\", \"forsal\", \"biker\", \"sweden\", \"footbal\", \"torqu\", \"miner\", \"processor\", \"infecti\", \"garag\", \"theoret\", \"deliveri\", \"itali\", \"switzerland\", \"click\", \"canadien\", \"intestin\", \"harley\", \"wagon\", \"alcohol\", \"corvett\", \"lesson\", \"chuck\", \"genesi\", \"sigh\", \"dive\", \"buy\", \"price\", \"ship\", \"offer\", \"sell\", \"music\", \"floppi\", \"disk\", \"tape\", \"brand\", \"manual\", \"drive\", \"card\", \"excel\", \"turbo\", \"condit\", \"packag\", \"ticket\", \"purchas\", \"interest\", \"channel\", \"ask\", \"item\", \"model\", \"origin\", \"plus\", \"includ\", \"modem\", \"hard\", \"best\", \"control\", \"trade\", \"mail\", \"good\", \"email\", \"work\", \"book\", \"power\", \"great\", \"penalti\", \"comic\", \"wolverin\", \"amiga\", \"bag\", \"hulk\", \"galaxi\", \"cloud\", \"arena\", \"bird\", \"gant\", \"spider\", \"mint\", \"erzurum\", \"silver\", \"pop\", \"mutant\", \"mazda\", \"mini\", \"shutout\", \"found\", \"scsi\", \"ninja\", \"replay\", \"marvel\", \"balloon\", \"oort\", \"aveng\", \"refere\", \"trek\", \"captain\", \"hawk\", \"flash\", \"green\", \"slash\", \"distanc\", \"tail\", \"star\", \"mask\", \"planet\", \"circl\", \"burst\", \"gamma\", \"appear\", \"black\", \"cover\", \"copi\", \"blue\", \"annual\", \"book\", \"hole\", \"stadium\", \"incred\", \"moon\", \"print\", \"forc\", \"white\", \"issu\", \"left\", \"earth\"], \"Freq\": [2208.0, 1629.0, 1712.0, 1451.0, 1397.0, 1542.0, 957.0, 1292.0, 1184.0, 1927.0, 796.0, 866.0, 792.0, 1372.0, 2533.0, 1607.0, 3032.0, 793.0, 1569.0, 622.0, 871.0, 708.0, 842.0, 1300.0, 3791.0, 728.0, 997.0, 2938.0, 896.0, 1514.0, 895.6075288383779, 593.9605715388963, 221.71764710600388, 178.50932624782607, 158.44630444330727, 153.97207397482222, 140.86413314556202, 134.56052617917993, 116.90477305128302, 113.087258600963, 109.33934302223594, 96.9023249037507, 94.44858635956759, 93.3735386301668, 88.31886156272621, 85.26855693836893, 96.90991552690059, 83.09714236095975, 81.82764393134573, 81.68669683402082, 79.80422834597407, 78.1677711067776, 75.43909946572968, 71.32049029713029, 70.64521538695759, 70.22253147632411, 66.59072700865079, 62.622998121259066, 60.689289900386235, 61.17962962836137, 277.4695998350905, 85.83048701721637, 484.80339136600094, 295.54780080160907, 197.48423767162234, 330.9682149455313, 264.2688887583061, 653.4927998717175, 398.07692632005643, 586.4060734599359, 1253.1323197274128, 255.02007158473467, 365.32657137383245, 482.13124989209575, 508.6017261356917, 1307.1859825095867, 934.4903082767581, 470.86695883775604, 329.02603234474634, 317.53220665735705, 564.1370495017093, 595.2875141580578, 616.3325471067988, 572.844353798893, 524.0445644371239, 1124.2945301966638, 969.1204986001276, 606.2370425299455, 888.6201846881679, 610.41980275448, 528.6897352546944, 599.847456926226, 377.9051419024935, 553.3681949095491, 416.7824493127019, 355.8772987965672, 415.90401930352044, 370.8752805776385, 700.4593043103068, 436.42004023037043, 363.73647219824164, 272.45472200158525, 246.39533728650505, 219.8442926022729, 153.93179600410033, 148.9051611426158, 122.00633781649327, 118.56027631026352, 117.44157174277282, 107.28255621741869, 103.69329311977333, 100.25079436694323, 96.40812457395585, 91.15776286247343, 86.85260314379373, 84.95254222134187, 83.66264969691461, 83.41925152592557, 83.12048418244753, 79.26286606064022, 77.45796229683465, 68.58084653992567, 68.22199875137093, 68.13348073680655, 76.31874259833708, 66.22816944092364, 65.75182696747346, 64.63616949170616, 184.77388416862442, 154.18525543756834, 254.83203109354918, 94.85853193781941, 212.37783967828923, 173.70201856086146, 391.52845670640653, 205.0692495447441, 490.30668540010544, 397.63328153504426, 752.1003366365744, 450.69805574948066, 310.38602141515423, 1564.369108983149, 1895.535756850956, 436.57230105987134, 1075.3225132064995, 178.84286076405522, 491.9688973743799, 367.43322731622123, 336.859130868769, 780.8952596659085, 319.1673881744476, 254.6943728651534, 667.1715148523408, 973.7166302718322, 650.0043407177839, 1108.9760005496062, 794.3542169297724, 388.87999489794026, 756.8578781401333, 465.5475181625614, 695.092860123747, 583.9058894873999, 418.6584488180821, 395.2787234428822, 511.1464019930246, 399.2356298765377, 475.01267574374975, 513.1329182833358, 465.3629581607926, 459.91053910929895, 1711.8307583658263, 662.9389390207095, 594.0671744070062, 458.3633407790358, 411.8808366561851, 367.9249553361309, 329.7704657109014, 324.1507981486189, 320.44103571350985, 317.74079112802974, 283.38523346478945, 278.7265351706382, 257.1671212833594, 250.63011921040484, 248.42468578596407, 211.18801113420145, 203.86748343893998, 192.07155400576175, 188.82421517147571, 168.47197497586075, 168.426003422081, 167.82830770529046, 164.25066161915558, 158.80755321437059, 141.1898451764135, 136.5995254736563, 133.67742719265527, 130.66752433589582, 130.27397070887065, 128.27265753497733, 581.5905165504005, 277.7823821003266, 152.1162461470071, 784.9819487165182, 451.3975475008976, 269.07578475958326, 285.1630768410337, 360.8358578334604, 435.2484067542195, 275.2569604545172, 356.12476725545287, 297.1900652000978, 764.1876063123805, 302.3067755730466, 1072.2111684499228, 577.1719186183655, 439.6189147283339, 416.28886440673347, 362.67779931438093, 471.93610898443274, 356.4060345434003, 328.67551284066144, 377.17491241941104, 313.08137213968627, 301.0202927614059, 573.4077207732844, 520.9171000088479, 519.037087847958, 508.7088479142514, 365.34648161920177, 335.9868416807183, 324.08211646141797, 319.65183516189546, 298.93183037425985, 269.77779015523356, 201.4524145225559, 185.62229581918052, 184.3015186798384, 173.07496030323534, 170.72397056134497, 168.69452250680075, 167.90635555649146, 157.27070004593804, 156.34974008768665, 151.8802784642676, 148.991011058335, 135.01191429309685, 125.02802787018844, 123.44836350011524, 123.17054368592191, 119.18541936756556, 115.33974899606052, 111.37598888233069, 111.22454713775491, 106.35942195850247, 413.9101004342016, 224.32064780090994, 528.3641810943566, 436.5558167221187, 1215.662906112502, 342.6264353084565, 304.6353917771523, 410.15628289640523, 513.0692650477145, 324.66093691413363, 404.4875968071768, 302.6089903452342, 442.7954512453519, 398.44211351465054, 303.51894650809993, 213.5277316857961, 381.39635453721644, 240.81159976732107, 384.6867826658948, 297.36280079869516, 328.9185258031853, 532.8986152568236, 324.2926551156914, 348.1686770971407, 304.4988992988785, 312.0765310023839, 728.0641871791871, 534.5049114009208, 495.0752010924425, 384.21308250285404, 348.79933246734544, 251.68163416230925, 244.5331462439724, 237.36607919207526, 235.42798142907716, 228.83918806167603, 215.38170231953043, 209.6251270230205, 177.40756440077408, 173.59856119074044, 168.95423599728764, 165.88739305322665, 164.26749066595266, 159.29088424611314, 151.54549916811249, 151.00491585002752, 147.49146423479968, 140.55454490658332, 136.45696651466392, 163.41914703045188, 134.45198682695607, 121.82552932256593, 116.5368910104507, 116.0791082541832, 111.18811069797216, 111.15266697300996, 1423.8798465135274, 312.5676571391102, 853.4101667007046, 466.8086382881163, 2104.6972231463037, 246.45593137183252, 1097.3236537598082, 239.58117897739058, 224.47997940472075, 234.4007785292863, 434.58742487351554, 240.26701062124855, 214.6868397682697, 383.87531769766787, 289.0547511519004, 237.69617289915658, 316.84413913692725, 974.0875070473003, 284.49031475470315, 251.39849821761533, 316.1050532224109, 280.68524316720493, 312.45154124949255, 259.10687283385397, 268.5335438645031, 248.2875797156572, 422.75006794756416, 414.04780122072543, 423.6760577918966, 218.93341761079185, 209.17144740613114, 156.18899718059834, 154.20120113217575, 121.00407853701911, 107.40457644410725, 98.84164002897752, 97.55724825399413, 102.36511775367443, 95.6266209580007, 80.42331732508322, 80.40392002806672, 79.5957957528007, 70.34300988691956, 59.55870546052972, 58.64256244340224, 57.40694968416098, 56.20467007555848, 54.3338928607924, 52.83987056668812, 50.92260404985102, 50.48500413385516, 50.33607395943579, 48.2503882414934, 45.09777357023064, 44.00702312737674, 43.980012267799005, 72.93685680502115, 187.30237449312708, 470.4958689179412, 196.54845703701272, 635.374841049677, 357.9774057408656, 162.01384530053974, 817.4289942370456, 535.8534559458402, 1107.5793655758905, 942.1532330222385, 285.49741913854535, 358.3581544302111, 493.7372317976109, 348.8510092471779, 278.765759731307, 918.5051549006512, 908.9425767727793, 716.1243843598326, 323.1118615816666, 239.65538983940914, 238.1699054606886, 724.5549901426424, 457.36825246900014, 431.1488364789594, 414.5771237500052, 577.251592017396, 416.7265615881892, 553.8679775888529, 364.14449020125613, 288.86700270248195, 430.1621074812191, 349.46356586725676, 305.4041404021961, 297.1818879792639, 575.9532682212347, 542.7554904880493, 495.6402901118273, 369.3876353821522, 294.4306409224549, 209.453910664798, 200.14229580079478, 196.33976447454003, 183.10668520301394, 170.90897674440038, 151.51501900226097, 147.885788872453, 122.2409351767422, 120.83915676661414, 118.41037099842718, 117.9360193790273, 110.2880982643651, 97.91711124382401, 93.90107415634893, 89.03777608661107, 88.25059277700144, 87.85626550032183, 86.72237228385232, 83.673819427504, 82.97299246736785, 80.31420603207529, 80.24049672021884, 79.56701791793638, 78.49297037029797, 76.85587783967624, 234.36582467622208, 378.3670660420082, 1529.0367391814234, 272.4596978975024, 715.7679610075935, 577.3522173164596, 175.57697286500468, 396.0583647099607, 212.05076905549075, 189.64151988300426, 503.3360266483525, 329.732002968861, 269.9752198947622, 204.15378900853543, 315.7073832427744, 233.5875593671871, 366.79489647395843, 485.90382532196946, 604.2435200341164, 581.0705708657163, 388.5134646095514, 346.82258149657997, 314.2610827333307, 472.91944283042886, 413.8682003550948, 443.4082397815082, 234.35434897497495, 243.0581138251888, 272.17151519872874, 303.4627421085477, 247.21000895568255, 247.91450836656298, 956.1473240215571, 791.26382603965, 445.64924835305777, 342.3548158987809, 233.8748033231671, 219.57109440579308, 215.71791536662286, 196.80530675749281, 158.0874625182176, 155.40635081086887, 130.46295258061338, 129.73444229020834, 116.2292131659899, 113.39680309091214, 107.59241910685196, 99.89824368396515, 93.6541169030531, 91.32500994613727, 79.26845904542299, 76.97685361600911, 75.78089514849268, 70.84559616776612, 70.07178911779818, 67.22984343130892, 565.5149060111962, 384.48885806018217, 45.489707188572446, 41.72027999760824, 40.166009207192474, 40.04689222529805, 805.015032252552, 275.2742594985864, 287.3775661595167, 443.7575081062159, 334.7624474571825, 162.586926739556, 232.45569591647183, 260.0388952927261, 426.03577751589944, 175.51015008180963, 714.0044056828635, 259.02418118134415, 349.6242658101098, 543.3042055828106, 235.41088089651006, 207.8332465656041, 230.85552652872374, 256.00901043159604, 283.7114518469436, 269.04630678205757, 206.78535061079677, 263.66290701502334, 265.0087517460653, 220.45456098699322, 213.07324741130256, 621.6653975504468, 174.15671848856272, 108.00322016496771, 87.281264340694, 82.50704236672101, 76.27669475550208, 73.58075935248394, 68.20204826175716, 66.99260975203845, 66.45749681329164, 66.35139617274096, 63.202005015162136, 59.72859335270192, 59.58781857091173, 57.81798680024323, 54.45721030575554, 54.40031388956435, 47.8681715353567, 46.712041379546854, 45.67580271591703, 45.234366446961005, 44.19539750853326, 43.93832975766835, 39.19150119214041, 38.02705468206102, 37.78249110159886, 37.54055318770481, 35.62064347667542, 34.883253090894804, 34.783268544846756, 121.34190620792668, 730.3740468000485, 393.51055243345274, 609.0667170990135, 499.14628611534545, 86.91955697755469, 111.59799829564821, 309.88508769082574, 219.4599066899127, 152.1638703065006, 292.8765984947698, 516.0220204938963, 301.6216512378099, 211.5256095711568, 85.65798172610094, 313.9281818250425, 291.8961264784493, 136.2034300432195, 142.017290448291, 387.3013705540644, 107.9934427824219, 320.6621901672467, 146.59091568078907, 204.47481961357371, 276.1759085540934, 157.71072866581665, 472.5760189089843, 114.04864134753655, 220.27208498612225, 245.474648404951, 227.3205875104136, 172.660151309674, 265.9252225855814, 261.6041495153617, 185.31591995905305, 209.94610898767831, 182.06033052657574, 176.79207875264152, 174.9099256386899, 211.749277380076, 169.16940634641534, 124.46127633023148, 123.32502845065, 116.38959326506561, 113.9792986304744, 100.5599242923285, 91.77545903662403, 87.47518186967366, 67.25162679373717, 65.69140838249982, 61.386814579629196, 58.61628926695979, 58.55279951889679, 57.85776555673414, 54.69301374232281, 53.861741748406935, 53.74104267964988, 50.900765717882955, 50.3577032769811, 49.009148236511095, 80.79950441901526, 46.636730692644946, 46.38149801490147, 44.9333778216659, 43.70865280047021, 43.17208847136675, 40.217693921146065, 39.98207599997151, 38.18264092709818, 121.02191792385524, 118.2078047778753, 68.99429254635896, 163.86737322461747, 52.492798476905904, 111.29686140639635, 65.86746877009236, 252.50991795253378, 90.13775886325172, 157.18251597525312, 82.52829857873883, 94.68467712035752, 70.3095094480372, 328.95707694170665, 205.77786926928945, 252.53880050789715, 274.3330876898553, 168.10117790366294, 98.50753991242915, 249.9109696545269, 93.83889437500589, 82.07658022970293, 79.27175804043544, 120.47347358280389, 112.47696111955388, 152.259346392378, 98.45673144027778, 108.23815433021454, 100.04115913902064, 91.10822383926106], \"Total\": [2208.0, 1629.0, 1712.0, 1451.0, 1397.0, 1542.0, 957.0, 1292.0, 1184.0, 1927.0, 796.0, 866.0, 792.0, 1372.0, 2533.0, 1607.0, 3032.0, 793.0, 1569.0, 622.0, 871.0, 708.0, 842.0, 1300.0, 3791.0, 728.0, 997.0, 2938.0, 896.0, 1514.0, 896.5360600576421, 594.8890937442811, 222.6464398978031, 179.43826541154868, 159.3749581595309, 154.90096387241582, 141.79289722084505, 135.4892638157829, 117.8339967545597, 114.01612851081184, 110.26815214889328, 97.83095624754363, 95.37710522371692, 94.30224532099533, 89.24735538669454, 86.19761579711235, 97.96990912371925, 84.0259308657141, 82.75648544077869, 82.61553686839846, 80.73295346652452, 79.09644819561024, 76.36773672280931, 72.24929371355357, 71.57404768439733, 71.15158744795458, 67.51953595272114, 63.55160504832545, 61.617980861869206, 62.124084913535654, 304.9276868657515, 89.91918695898684, 604.4439232014392, 360.44832606335024, 233.69667433740622, 426.8729787483889, 330.653899528644, 972.5686582002683, 576.1661817128019, 960.3266100144963, 2533.0502292049223, 345.2508278286828, 545.8578968332848, 799.8508419243344, 861.6435027063562, 3032.4797664236967, 1966.9847881478836, 795.7573232125686, 501.4670129445877, 492.83234442549127, 1095.6210376101048, 1216.5129953064636, 1283.9169146630588, 1177.7966526886112, 1058.4695616566669, 3791.4382220045886, 3203.9064362459594, 1514.9297363814396, 2938.7147307647956, 1542.8183823709405, 1403.7091429998895, 1926.0625844930187, 733.0004569937655, 1976.6357025050424, 1005.9524994609949, 691.8686276640424, 1594.7829940214106, 1007.7106516952151, 701.3907415616827, 437.351512569737, 364.6679694865421, 273.3862179809972, 247.32679452033133, 220.7757948937146, 154.86357164348408, 149.836647303171, 122.93783728814239, 119.49173630400783, 118.37536864166003, 108.21417759882786, 104.6248733250607, 101.18260473999565, 97.33966006943007, 92.08923056779676, 87.78418606538784, 85.88405778408911, 84.59416404028988, 84.35124560957449, 84.05209618847078, 80.19453151761677, 78.39345212638737, 69.5122797105202, 69.15360938205116, 69.06505556883877, 77.36795771040373, 67.15978567546406, 66.68376031578069, 65.56779530512637, 191.97997598409506, 160.92611532206598, 273.10853278041765, 98.02343970707483, 240.58089118104724, 193.54308722289878, 494.91837444461544, 238.38168814195475, 657.9031793433821, 527.447304252404, 1129.0322995733525, 629.0819233041384, 405.0692924870923, 2938.7147307647956, 3791.4382220045886, 635.4517002954353, 2003.4716635427176, 213.34326097649793, 816.7505437206539, 554.5430455029194, 495.55121124934914, 1542.8183823709405, 475.6921123805322, 347.6291975304965, 1413.356353832559, 2533.0502292049223, 1394.2381074879993, 3203.9064362459594, 1926.0625844930187, 664.7920462434759, 1976.6357025050424, 934.196445853243, 2069.80823414823, 1701.6300953551747, 902.8609665298653, 798.9660305820131, 1594.7829940214106, 845.1803448442989, 1463.5054353229518, 2981.7088769580487, 1966.9847881478836, 3032.4797664236967, 1712.7644570635427, 663.8726321285542, 595.0008743399848, 459.29705874410854, 412.8145762976987, 368.8586494108961, 330.7041652533913, 325.0844901807541, 321.3747712215115, 318.67449825756444, 284.3189527843906, 279.66023666599295, 258.101082695911, 251.56384150219486, 249.358428613512, 212.12170378746126, 204.80117230271586, 193.005402317121, 189.7579194635964, 169.40566126317154, 169.35970278580282, 168.76200708519121, 165.184362418549, 159.74128054752276, 142.12359992603183, 137.5332976214523, 134.61114307218384, 131.60142684819283, 131.2077008496447, 129.20650860396051, 592.5922937656328, 280.96136933616714, 154.28525408077272, 884.5493398995213, 505.95158337251263, 290.71202143563204, 322.9910314358084, 429.88023717240134, 553.8478238192121, 321.9547909285096, 468.5804591808752, 365.823076413506, 1463.5054353229518, 395.0013796022792, 3032.4797664236967, 1292.0098168366897, 849.6855505790347, 855.1284317302323, 665.9189927837715, 1403.7091429998895, 903.1711147905456, 863.463008173437, 2981.7088769580487, 862.2378363891553, 597.237892641266, 574.3297515498178, 521.8391091514377, 519.9591801360011, 509.6308317625022, 366.26847423334516, 336.90883427616063, 325.0040831831115, 320.57380047307464, 299.8538011321154, 270.69988839425173, 202.37443656257634, 186.5443385235826, 185.22348204175424, 173.9969205065709, 171.64600489519438, 169.6164894756454, 168.8283344106969, 158.19295571222676, 157.27173178737897, 152.80225215903258, 149.91388558357863, 135.9338933555926, 125.95058952030308, 124.3705393018382, 124.09251083411507, 120.10740917605126, 116.26172392331142, 112.29802786618077, 112.14656675874765, 107.28138540425907, 419.58567820564343, 227.49027614058852, 544.315709806726, 461.2368547372562, 1372.9193593133643, 386.09132626512803, 340.37217239440287, 501.1657302176879, 683.7320341794749, 416.6823921573173, 592.6238748571017, 406.1132708297377, 818.6050846846573, 730.662411939126, 484.0083676404023, 263.6936832393934, 820.6194996934013, 334.2792488341526, 903.1711147905456, 561.8134394648932, 750.3473706748724, 2981.7088769580487, 913.367486995266, 1607.4932315910298, 902.6324653764221, 1569.7251048477283, 728.9944132567904, 535.4355170000867, 496.0053672172536, 385.1616902289652, 349.72951593296415, 252.6118079286113, 245.4635476355968, 238.29620465169037, 236.3809081046529, 229.76935975226394, 216.3118151228653, 210.55530575696727, 178.33769181713305, 174.52883775564862, 169.884373299227, 166.81755706098414, 165.19768252640407, 160.2210020939241, 152.47567097305824, 151.93523725456865, 148.4215679405602, 141.48475246122362, 137.3871262775626, 164.54511398078247, 135.38219783948904, 122.75564527391798, 117.4670001887956, 117.0092690942459, 112.11824961979302, 112.08276781447017, 1451.0979335503487, 315.8504980172376, 871.3902530705102, 474.475248182087, 2208.613347130888, 250.3695780929152, 1184.2002178001162, 248.51372541289504, 233.23966866541096, 251.12127292776464, 515.1376367930193, 267.5726367298349, 241.89139791661455, 561.1574988144831, 396.8024888028474, 294.5603166042633, 471.7527486621967, 2981.7088769580487, 448.42315356544395, 380.51126754762646, 1283.9169146630588, 889.3753360841836, 1976.6357025050424, 1009.8951526220654, 3203.9064362459594, 2533.0502292049223, 423.6697282325457, 414.967643182183, 424.7457271078242, 219.85323781051648, 210.091157225182, 157.10876988628522, 155.12092396190707, 121.92379649568029, 108.32469219018186, 99.76145187513106, 98.47708539774713, 103.33422098332937, 96.54640125848739, 81.34316371707637, 81.32366946084048, 80.51542625516973, 71.26283567633814, 60.478517626785305, 59.56235209574498, 58.32670064342585, 57.12460559618434, 55.253594827724164, 53.75964286929212, 51.84252445466896, 51.40468269775429, 51.2557898469452, 49.17006780999775, 46.017700762036334, 44.92711881519401, 44.89972925553036, 74.63841249665143, 197.91074915937602, 522.8842465757796, 211.14432785880277, 719.5822383319882, 402.1341866701366, 176.84322454444913, 997.7599872507147, 635.1594870036056, 1397.569362437044, 1300.5746394750015, 346.29978076633984, 457.85949578671955, 687.0586080726669, 471.7253202486, 362.2257760202529, 1542.416075313607, 1569.7251048477283, 1210.8398724320114, 454.77309524569284, 318.86363693113304, 317.283529713002, 1514.9297363814396, 809.1390076827502, 791.1666541662655, 749.0175725216274, 1607.4932315910298, 1010.7702095228051, 1927.6952637171237, 958.8165127489228, 522.3412913568136, 1556.2410594164824, 1091.3825147671428, 1062.434927564373, 777.8741593907853, 576.8728452333736, 543.6748801744416, 496.559702562523, 370.30706261004417, 295.3500219145175, 210.37330481359336, 201.06173865447624, 197.25917127865875, 184.02614802768574, 171.82835997657224, 152.43442941443672, 148.80516998141294, 123.16038858664011, 121.75855839186393, 119.32984893963497, 118.85539592219793, 111.20748152889799, 98.83659034573711, 94.82049511529729, 89.95769218139735, 89.17025996277165, 88.77566525990508, 87.64219811526142, 84.5933796450618, 83.89240210827602, 81.23361024373854, 81.15988214454059, 80.48641121643317, 79.41236227543166, 77.77527932207684, 238.59385053760056, 387.62010671143963, 1629.8007990101733, 293.3464311290858, 842.2366574300137, 709.701199821923, 194.04913398575695, 491.05695840856333, 241.62946204338746, 227.67401247794592, 770.1096919382899, 458.4064459602497, 358.3274840279277, 252.42297119498713, 459.5593117153454, 317.68608803899065, 612.286914199693, 997.6788179890816, 1607.4932315910298, 1542.416075313607, 853.1224288726648, 722.0667193676151, 609.4787765621535, 1927.6952637171237, 1594.7829940214106, 2069.80823414823, 352.3356211359178, 437.1559952872007, 791.1666541662655, 2003.4716635427176, 1174.1619878748584, 3791.4382220045886, 957.0737257658352, 792.1903336966406, 446.57568359109143, 343.2812072827783, 234.8011987596516, 220.49751902566146, 216.64437307305084, 197.7606408800382, 159.01387424599767, 156.33277186627828, 131.38948898400952, 130.66089899867836, 117.15563081981821, 114.32320439920386, 108.51942534426081, 100.82556217371679, 94.5806145548466, 92.25148573295918, 80.19489344859282, 77.90325124250762, 76.70729846030727, 71.77200720340376, 70.99878213815533, 68.15872521179188, 574.6341324710604, 391.8107658097501, 46.41719898848988, 42.64689088773017, 41.09317862268687, 40.97373813363939, 866.7152911977371, 299.95079695311296, 319.2718392942508, 511.67324699898273, 402.1817349205124, 180.3470354583196, 276.67597373141996, 321.4009478892116, 596.1207091448784, 218.13955413216055, 1292.0098168366897, 367.91108733336796, 568.3853393341251, 1060.178861133845, 335.3722892852805, 296.81792978498436, 388.8752221170076, 478.32403611852027, 809.1390076827502, 853.7214113624839, 375.538135310328, 1556.2410594164824, 1701.6300953551747, 818.6050846846573, 1569.7251048477283, 622.591665405635, 175.08304185882557, 108.92952319658175, 88.20770517474975, 83.43368507898595, 77.20289390061552, 74.50711273291721, 69.12838818009554, 67.91907435697976, 67.38377164342434, 67.2800840544314, 64.12841691852739, 60.65686461392006, 60.514343216956256, 58.7447090256167, 55.38367377652501, 55.326739113239775, 48.79467845427525, 47.63915247819415, 46.602513566361765, 46.16141661305222, 45.12166969709143, 44.86460868956268, 40.117976814436794, 38.95334566638647, 38.71023448597663, 38.46693960820141, 36.54690791435301, 35.80977966674767, 35.70994393718853, 127.33260147894308, 796.0837769398948, 425.43245826430234, 708.9194452987766, 578.4509538253244, 94.06671523303572, 123.83667589538388, 390.0083040271564, 268.73713161025756, 179.0421919404888, 401.30187419606546, 793.1468137075987, 430.00514484301027, 283.78746842493035, 97.38164790018044, 540.8530132889412, 503.92693875583814, 184.18260753913978, 202.67155896482203, 926.1732609883006, 141.08799634435883, 753.7098123142064, 230.6506018337166, 391.9451374881853, 638.0498288852078, 271.05839899521754, 1927.6952637171237, 157.83139895539557, 607.6120330802385, 843.2369986354635, 788.1620512025476, 414.29376280788347, 1397.569362437044, 1976.6357025050424, 687.0586080726669, 2069.80823414823, 880.0247594116884, 991.3283185556737, 922.2555584311373, 212.6682281233787, 170.0881905966742, 125.38004265390624, 124.24414886118436, 117.30845426007505, 114.89806554696855, 101.47881332740535, 92.69429265508894, 88.39414432990732, 68.17058079011035, 66.61034537440898, 62.30559807305242, 59.535159466730825, 59.47204603555726, 58.77948724037508, 55.61223882954046, 54.78052467014607, 54.66011574999351, 51.819691844438346, 51.27669621000114, 49.928848356633, 82.35708791143188, 47.55560319909123, 47.300567883987526, 45.85221228696897, 44.62750309832839, 44.090868861975295, 41.13654131235914, 40.9011289736213, 39.10149807494604, 129.0672278369358, 128.07664656344227, 72.9531680121138, 189.9707136931679, 54.62065632643443, 127.91607988166518, 71.228920839173, 351.61567733268987, 103.28567862902233, 202.8479292595362, 94.73692994524299, 113.01219818328633, 77.68311239745412, 628.439468901689, 352.5903183063723, 513.57816239126, 630.6330164449121, 383.05595311108334, 150.15314729853708, 880.0247594116884, 146.16583758187903, 108.87264096853724, 102.29464448834271, 287.55354682943056, 275.2673303162747, 683.5186689877859, 321.46069285915974, 724.2315065868269, 792.4432584459696, 416.6823921573173], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.7546, -5.1653, -6.1507, -6.3674, -6.4867, -6.5153, -6.6043, -6.6501, -6.7907, -6.8239, -6.8576, -6.9784, -7.004, -7.0155, -7.0711, -7.1063, -6.9783, -7.1321, -7.1475, -7.1492, -7.1725, -7.1932, -7.2287, -7.2849, -7.2944, -7.3004, -7.3535, -7.4149, -7.4463, -7.4383, -5.9264, -7.0997, -5.3683, -5.8632, -6.2664, -5.75, -5.9751, -5.0697, -5.5654, -5.1781, -4.4187, -6.0107, -5.6513, -5.3739, -5.3204, -4.3764, -4.7121, -5.3975, -5.7559, -5.7915, -5.2168, -5.163, -5.1283, -5.2015, -5.2905, -4.5272, -4.6757, -5.1448, -4.7624, -5.1379, -5.2817, -5.1554, -5.6174, -5.236, -5.5195, -5.6775, -5.5216, -5.6362, -4.9679, -5.441, -5.6232, -5.9121, -6.0127, -6.1267, -6.4831, -6.5163, -6.7155, -6.7442, -6.7537, -6.8441, -6.8782, -6.9119, -6.951, -7.007, -7.0554, -7.0775, -7.0928, -7.0957, -7.0993, -7.1468, -7.1699, -7.2916, -7.2968, -7.2981, -7.1847, -7.3265, -7.3337, -7.3508, -6.3005, -6.4815, -5.979, -6.9672, -6.1612, -6.3623, -5.5495, -6.1963, -5.3246, -5.5341, -4.8967, -5.4088, -5.7818, -4.1644, -3.9724, -5.4407, -4.5392, -6.3331, -5.3212, -5.6131, -5.6999, -4.8592, -5.7539, -5.9795, -5.0166, -4.6385, -5.0426, -4.5084, -4.8421, -5.5563, -4.8904, -5.3764, -4.9756, -5.1499, -5.4826, -5.54, -5.283, -5.5301, -5.3563, -5.2791, -5.3768, -5.3886, -4.0036, -4.9522, -5.0619, -5.3212, -5.4282, -5.541, -5.6505, -5.6677, -5.6792, -5.6877, -5.8021, -5.8187, -5.8992, -5.9249, -5.9338, -6.0962, -6.1314, -6.191, -6.2081, -6.3221, -6.3224, -6.326, -6.3475, -6.3812, -6.4988, -6.5319, -6.5535, -6.5763, -6.5793, -6.5947, -5.0831, -5.8221, -6.4243, -4.7832, -5.3366, -5.8539, -5.7958, -5.5605, -5.373, -5.8312, -5.5736, -5.7545, -4.8101, -5.7375, -4.4714, -5.0908, -5.363, -5.4175, -5.5554, -5.2921, -5.5728, -5.6538, -5.5162, -5.7024, -5.7417, -4.954, -5.05, -5.0536, -5.0737, -5.4047, -5.4885, -5.5246, -5.5384, -5.6054, -5.708, -6.0, -6.0819, -6.089, -6.1519, -6.1655, -6.1775, -6.1822, -6.2476, -6.2535, -6.2825, -6.3017, -6.4002, -6.477, -6.4898, -6.492, -6.5249, -6.5577, -6.5927, -6.594, -6.6388, -5.2799, -5.8925, -5.0358, -5.2267, -4.2025, -5.4689, -5.5865, -5.289, -5.0652, -5.5228, -5.303, -5.5931, -5.2125, -5.318, -5.5901, -5.9418, -5.3617, -5.8216, -5.3532, -5.6106, -5.5098, -5.0273, -5.5239, -5.4529, -5.5869, -5.5623, -4.4681, -4.7772, -4.8538, -5.1073, -5.204, -5.5303, -5.5592, -5.5889, -5.5971, -5.6255, -5.6861, -5.7132, -5.8801, -5.9018, -5.9289, -5.9472, -5.957, -5.9878, -6.0376, -6.0412, -6.0647, -6.1129, -6.1425, -5.9622, -6.1573, -6.2559, -6.3003, -6.3042, -6.3473, -6.3476, -3.7974, -5.3137, -4.3093, -4.9126, -3.4066, -5.5513, -4.0579, -5.5796, -5.6447, -5.6015, -4.9841, -5.5768, -5.6893, -5.1082, -5.3919, -5.5875, -5.3001, -4.177, -5.4078, -5.5315, -5.3024, -5.4213, -5.3141, -5.5013, -5.4655, -5.5439, -4.9655, -4.9863, -4.9633, -5.6235, -5.6691, -5.9612, -5.974, -6.2164, -6.3356, -6.4187, -6.4318, -6.3837, -6.4518, -6.6249, -6.6252, -6.6353, -6.7589, -6.9253, -6.9408, -6.9621, -6.9832, -7.0171, -7.045, -7.0819, -7.0906, -7.0935, -7.1358, -7.2034, -7.2279, -7.2285, -6.7226, -5.7795, -4.8585, -5.7313, -4.558, -5.1318, -5.9246, -4.3061, -4.7284, -4.0023, -4.1641, -5.358, -5.1307, -4.8102, -5.1576, -5.3819, -4.1895, -4.2, -4.4384, -5.2342, -5.533, -5.5393, -4.4267, -4.8868, -4.9458, -4.985, -4.654, -4.9798, -4.6953, -5.1147, -5.3463, -4.9481, -5.1558, -5.2906, -5.3179, -4.4355, -4.4949, -4.5857, -4.8797, -5.1065, -5.447, -5.4925, -5.5117, -5.5815, -5.6504, -5.7708, -5.7951, -5.9855, -5.9971, -6.0174, -6.0214, -6.0884, -6.2074, -6.2493, -6.3025, -6.3113, -6.3158, -6.3288, -6.3646, -6.373, -6.4056, -6.4065, -6.4149, -6.4285, -6.4496, -5.3346, -4.8557, -3.4591, -5.184, -4.2182, -4.4331, -5.6235, -4.81, -5.4347, -5.5464, -4.5703, -4.9932, -5.1932, -5.4727, -5.0367, -5.338, -4.8867, -4.6055, -4.3876, -4.4267, -4.8292, -4.9427, -5.0413, -4.6326, -4.766, -4.697, -5.3347, -5.2982, -5.1851, -5.0763, -5.2813, -5.2784, -3.8462, -4.0354, -4.6095, -4.8732, -5.2543, -5.3174, -5.3351, -5.4268, -5.6459, -5.663, -5.838, -5.8436, -5.9535, -5.9782, -6.0307, -6.1049, -6.1695, -6.1946, -6.3362, -6.3656, -6.3812, -6.4486, -6.4595, -6.5009, -4.3713, -4.7571, -6.8916, -6.9781, -7.016, -7.019, -4.0182, -5.0913, -5.0483, -4.6138, -4.8956, -5.6179, -5.2604, -5.1482, -4.6545, -5.5414, -4.1382, -5.1521, -4.8522, -4.4114, -5.2477, -5.3723, -5.2673, -5.1639, -5.0611, -5.1142, -5.3774, -5.1344, -5.1293, -5.3134, -5.3474, -3.875, -5.1474, -5.6252, -5.8382, -5.8945, -5.973, -6.009, -6.0849, -6.1028, -6.1108, -6.1124, -6.161, -6.2176, -6.2199, -6.2501, -6.31, -6.311, -6.4389, -6.4634, -6.4858, -6.4955, -6.5188, -6.5246, -6.6389, -6.6691, -6.6755, -6.6819, -6.7344, -6.7554, -6.7582, -5.5088, -3.7138, -4.3323, -3.8954, -4.0945, -5.8424, -5.5925, -4.5712, -4.9162, -5.2824, -4.6276, -4.0612, -4.5982, -4.953, -5.857, -4.5582, -4.631, -5.3932, -5.3514, -4.3482, -5.6253, -4.537, -5.3197, -4.9869, -4.6863, -5.2466, -4.1492, -5.5707, -4.9125, -4.8042, -4.881, -5.156, -4.7242, -4.7405, -5.0853, -4.9605, -5.103, -5.1324, -5.1431, -4.5427, -4.7672, -5.0741, -5.0833, -5.1412, -5.1621, -5.2873, -5.3788, -5.4267, -5.6897, -5.7131, -5.7809, -5.8271, -5.8282, -5.8401, -5.8964, -5.9117, -5.9139, -5.9682, -5.9789, -6.0061, -5.5061, -6.0557, -6.0612, -6.0929, -6.1206, -6.1329, -6.2038, -6.2097, -6.2557, -5.1021, -5.1257, -5.6641, -4.799, -5.9374, -5.1859, -5.7105, -4.3666, -5.3968, -4.8407, -5.485, -5.3475, -5.6452, -4.1022, -4.5713, -4.3665, -4.2838, -4.7735, -5.308, -4.377, -5.3565, -5.4904, -5.5252, -5.1067, -5.1753, -4.8725, -5.3085, -5.2138, -5.2925, -5.386], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.8271, 1.8265, 1.8239, 1.8229, 1.8223, 1.8221, 1.8215, 1.8212, 1.8202, 1.8199, 1.8196, 1.8186, 1.8183, 1.8182, 1.8176, 1.8173, 1.8172, 1.817, 1.8168, 1.8168, 1.8165, 1.8163, 1.8159, 1.8152, 1.815, 1.815, 1.8142, 1.8134, 1.8129, 1.8128, 1.7337, 1.7816, 1.6075, 1.6296, 1.6597, 1.5736, 1.604, 1.4305, 1.4583, 1.3348, 1.1243, 1.5252, 1.4265, 1.3219, 1.3009, 0.9866, 1.0838, 1.3034, 1.4067, 1.3885, 1.1643, 1.1134, 1.0942, 1.1073, 1.1251, 0.6125, 0.6324, 0.9122, 0.632, 0.9009, 0.8516, 0.6615, 1.1656, 0.555, 0.947, 1.1633, 0.4841, 0.8285, 1.8592, 1.8584, 1.858, 1.8571, 1.8568, 1.8563, 1.8545, 1.8543, 1.853, 1.8527, 1.8526, 1.8519, 1.8516, 1.8513, 1.8509, 1.8504, 1.8499, 1.8497, 1.8495, 1.8494, 1.8494, 1.8489, 1.8486, 1.8471, 1.847, 1.847, 1.8469, 1.8466, 1.8465, 1.8462, 1.8223, 1.8178, 1.7913, 1.8277, 1.7359, 1.7524, 1.6262, 1.71, 1.5665, 1.578, 1.4543, 1.5271, 1.5943, 1.2301, 1.1673, 1.4852, 1.2383, 1.6842, 1.3536, 1.449, 1.4746, 1.1796, 1.4615, 1.5495, 1.1099, 0.9045, 1.0974, 0.7996, 0.9749, 1.3244, 0.9006, 1.1641, 0.7694, 0.791, 1.092, 1.1568, 0.7227, 1.1106, 0.7353, 0.1008, 0.4191, -0.0255, 1.9307, 1.9299, 1.9297, 1.9292, 1.929, 1.9287, 1.9284, 1.9284, 1.9283, 1.9283, 1.928, 1.9279, 1.9276, 1.9275, 1.9275, 1.9268, 1.9267, 1.9264, 1.9263, 1.9257, 1.9257, 1.9257, 1.9256, 1.9254, 1.9247, 1.9244, 1.9243, 1.9241, 1.9241, 1.924, 1.9125, 1.9199, 1.9171, 1.8118, 1.8172, 1.8539, 1.8067, 1.7562, 1.6903, 1.7746, 1.6568, 1.7235, 1.2815, 1.6638, 0.8916, 1.1254, 1.2723, 1.2114, 1.3236, 0.8412, 1.0014, 0.9654, -0.1363, 0.9182, 1.2461, 2.073, 2.0728, 2.0728, 2.0728, 2.0721, 2.0718, 2.0717, 2.0717, 2.0715, 2.0712, 2.07, 2.0696, 2.0696, 2.0693, 2.0692, 2.0691, 2.0691, 2.0687, 2.0687, 2.0685, 2.0684, 2.0678, 2.0672, 2.0671, 2.0671, 2.0669, 2.0666, 2.0663, 2.0663, 2.066, 2.061, 2.0606, 2.0448, 2.0196, 1.9529, 1.9551, 1.9637, 1.8742, 1.7874, 1.825, 1.6926, 1.7804, 1.4601, 1.4682, 1.6079, 1.8636, 1.3084, 1.7466, 1.2211, 1.4384, 1.2499, 0.3527, 1.0391, 0.5448, 0.9879, 0.4592, 2.3204, 2.3199, 2.3198, 2.3192, 2.319, 2.318, 2.3179, 2.3177, 2.3176, 2.3176, 2.3173, 2.3172, 2.3164, 2.3163, 2.3162, 2.3161, 2.316, 2.3158, 2.3155, 2.3155, 2.3154, 2.3151, 2.3149, 2.3148, 2.3148, 2.314, 2.3137, 2.3137, 2.3133, 2.3133, 2.3027, 2.3112, 2.3008, 2.3054, 2.2735, 2.3059, 2.2455, 2.285, 2.2834, 2.2528, 2.1516, 2.214, 2.2023, 1.942, 2.0048, 2.1072, 1.9236, 1.2029, 1.8666, 1.9072, 0.9201, 1.1684, 0.477, 0.9613, -0.1575, -0.0009, 2.3657, 2.3657, 2.3654, 2.3637, 2.3635, 2.3621, 2.362, 2.3604, 2.3594, 2.3587, 2.3585, 2.3585, 2.3583, 2.3565, 2.3565, 2.3564, 2.3549, 2.3526, 2.3524, 2.352, 2.3517, 2.3511, 2.3507, 2.35, 2.3499, 2.3498, 2.349, 2.3477, 2.3472, 2.3472, 2.3449, 2.3128, 2.2623, 2.2963, 2.2435, 2.2516, 2.2803, 2.1686, 2.1979, 2.1354, 2.0455, 2.1749, 2.1229, 2.0375, 2.0662, 2.106, 1.8496, 1.8215, 1.8427, 2.0261, 2.0824, 2.0811, 1.6304, 1.7974, 1.7609, 1.7764, 1.3438, 1.4819, 1.1208, 1.3998, 1.7756, 1.0821, 1.2291, 1.1212, 1.4057, 2.587, 2.5869, 2.5868, 2.5862, 2.5855, 2.5843, 2.5841, 2.584, 2.5836, 2.5833, 2.5826, 2.5824, 2.5811, 2.5811, 2.5809, 2.5809, 2.5803, 2.5793, 2.5789, 2.5784, 2.5783, 2.5782, 2.5781, 2.5777, 2.5776, 2.5773, 2.5772, 2.5771, 2.577, 2.5767, 2.5708, 2.5645, 2.5248, 2.5148, 2.4259, 2.3822, 2.4886, 2.3736, 2.4581, 2.4059, 2.1634, 2.2592, 2.3055, 2.3764, 2.2132, 2.2811, 2.0762, 1.8692, 1.6102, 1.6124, 1.8021, 1.8553, 1.9263, 1.1835, 1.2397, 1.0479, 2.1809, 2.0016, 1.5216, 0.7013, 1.0306, -0.1388, 2.6701, 2.6699, 2.669, 2.6684, 2.6671, 2.6669, 2.6668, 2.6663, 2.6653, 2.6652, 2.664, 2.664, 2.6632, 2.663, 2.6625, 2.6619, 2.6613, 2.661, 2.6595, 2.6591, 2.659, 2.6581, 2.658, 2.6574, 2.6551, 2.6522, 2.6509, 2.6491, 2.6483, 2.6482, 2.5973, 2.5853, 2.5659, 2.5287, 2.4876, 2.5674, 2.497, 2.4592, 2.3352, 2.4537, 2.078, 2.3202, 2.1852, 2.0026, 2.3172, 2.3147, 2.1496, 2.046, 1.6231, 1.5164, 2.0744, 0.8957, 0.8115, 1.3592, 0.6741, 3.0713, 3.0675, 3.0643, 3.0622, 3.0616, 3.0607, 3.0603, 3.0593, 3.0591, 3.059, 3.0589, 3.0582, 3.0574, 3.0574, 3.0569, 3.0559, 3.0559, 3.0536, 3.0531, 3.0527, 3.0525, 3.0521, 3.0519, 3.0494, 3.0487, 3.0485, 3.0484, 3.0471, 3.0466, 3.0465, 3.0246, 2.9866, 2.9948, 2.921, 2.9253, 2.9938, 2.9687, 2.8428, 2.8702, 2.9101, 2.7578, 2.6429, 2.7182, 2.7789, 2.9445, 2.5288, 2.5268, 2.771, 2.7172, 2.2009, 2.8055, 2.2182, 2.6195, 2.4221, 2.2354, 2.5312, 1.6669, 2.7479, 2.0581, 1.8387, 1.8295, 2.1975, 1.4135, 1.0505, 1.7624, 0.7844, 1.4972, 1.3487, 1.4102, 3.4777, 3.4767, 3.4747, 3.4746, 3.4742, 3.474, 3.473, 3.4721, 3.4716, 3.4685, 3.4682, 3.4672, 3.4665, 3.4665, 3.4663, 3.4654, 3.4652, 3.4651, 3.4642, 3.464, 3.4635, 3.463, 3.4626, 3.4624, 3.4618, 3.4613, 3.461, 3.4595, 3.4593, 3.4583, 3.4177, 3.4019, 3.4263, 3.3343, 3.4423, 3.3429, 3.4038, 3.151, 3.3459, 3.227, 3.3441, 3.3051, 3.3823, 2.8348, 2.9436, 2.7722, 2.6497, 2.6585, 3.0605, 2.2232, 3.0389, 3.1995, 3.2271, 2.6121, 2.5871, 1.9804, 2.2988, 1.5813, 1.4125, 1.9618]}, \"token.table\": {\"Topic\": [2, 1, 2, 4, 5, 6, 7, 8, 1, 3, 4, 6, 10, 3, 4, 6, 8, 3, 4, 8, 1, 2, 5, 8, 4, 2, 9, 6, 8, 8, 10, 8, 3, 4, 6, 10, 6, 4, 1, 3, 4, 5, 6, 7, 8, 10, 4, 6, 7, 8, 3, 4, 5, 8, 9, 1, 3, 3, 6, 10, 7, 3, 1, 7, 1, 3, 3, 3, 3, 9, 1, 1, 2, 3, 6, 7, 8, 9, 1, 3, 8, 8, 6, 2, 2, 4, 6, 7, 8, 9, 10, 3, 3, 3, 10, 3, 10, 5, 5, 2, 1, 2, 3, 4, 5, 8, 4, 1, 2, 4, 5, 6, 7, 9, 1, 2, 4, 5, 7, 8, 2, 9, 10, 7, 4, 6, 2, 3, 4, 7, 8, 10, 2, 3, 8, 2, 5, 7, 10, 1, 2, 3, 4, 6, 7, 9, 10, 3, 5, 2, 2, 9, 5, 5, 3, 10, 2, 7, 8, 8, 9, 6, 8, 2, 5, 9, 4, 4, 3, 10, 2, 1, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 2, 1, 2, 3, 4, 7, 1, 2, 1, 3, 4, 5, 6, 1, 2, 3, 5, 7, 8, 2, 3, 8, 9, 8, 5, 3, 4, 7, 8, 4, 9, 6, 8, 5, 10, 1, 3, 8, 10, 8, 1, 2, 3, 4, 5, 8, 9, 9, 6, 7, 4, 3, 8, 5, 8, 10, 5, 2, 6, 7, 8, 1, 2, 4, 7, 9, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 6, 8, 6, 7, 6, 8, 10, 1, 2, 3, 4, 9, 10, 1, 4, 6, 6, 7, 1, 2, 3, 4, 6, 7, 8, 9, 3, 6, 7, 8, 10, 9, 1, 3, 2, 3, 4, 8, 9, 10, 8, 6, 8, 8, 8, 6, 7, 4, 6, 7, 8, 2, 8, 8, 7, 1, 3, 4, 5, 8, 1, 3, 7, 9, 6, 2, 2, 5, 3, 4, 5, 6, 7, 8, 6, 7, 8, 5, 4, 1, 2, 3, 4, 5, 6, 7, 8, 4, 6, 8, 9, 7, 1, 10, 4, 6, 7, 8, 10, 9, 3, 4, 5, 6, 2, 3, 8, 6, 2, 3, 9, 4, 8, 4, 10, 1, 1, 1, 2, 3, 4, 7, 8, 6, 9, 10, 8, 3, 5, 8, 2, 4, 8, 2, 6, 1, 5, 6, 7, 10, 8, 9, 1, 2, 3, 4, 7, 10, 1, 3, 4, 8, 2, 4, 5, 8, 9, 7, 7, 8, 1, 2, 3, 4, 5, 8, 5, 3, 6, 7, 8, 6, 3, 10, 8, 9, 4, 5, 7, 9, 1, 3, 7, 8, 10, 2, 9, 10, 1, 4, 6, 7, 8, 10, 5, 9, 4, 10, 10, 9, 7, 2, 8, 9, 3, 1, 2, 4, 5, 7, 8, 9, 1, 2, 3, 5, 7, 8, 1, 3, 4, 5, 8, 10, 5, 1, 2, 4, 5, 6, 7, 8, 9, 3, 8, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 3, 3, 5, 7, 9, 10, 1, 2, 3, 4, 6, 8, 10, 8, 1, 2, 3, 5, 7, 8, 1, 2, 3, 5, 8, 9, 9, 4, 10, 3, 4, 1, 2, 3, 5, 6, 2, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 3, 4, 5, 6, 1, 5, 1, 2, 6, 10, 2, 10, 6, 1, 2, 4, 7, 8, 1, 2, 3, 6, 8, 4, 1, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 8, 1, 8, 10, 4, 9, 2, 4, 6, 7, 1, 3, 4, 6, 7, 8, 5, 2, 4, 8, 1, 2, 3, 4, 6, 8, 9, 6, 7, 6, 9, 1, 1, 3, 1, 1, 1, 3, 4, 6, 8, 10, 3, 9, 1, 4, 6, 7, 9, 2, 1, 3, 1, 3, 5, 7, 8, 6, 1, 2, 3, 5, 7, 10, 1, 3, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 4, 5, 5, 10, 1, 1, 1, 1, 2, 3, 5, 7, 10, 1, 3, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 7, 2, 3, 4, 5, 6, 7, 9, 10, 6, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 2, 3, 7, 7, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 5, 4, 6, 2, 6, 9, 1, 2, 3, 4, 5, 7, 8, 7, 2, 3, 4, 5, 6, 7, 8, 2, 6, 7, 9, 4, 10, 8, 10, 3, 10, 6, 1, 2, 5, 8, 10, 10, 1, 2, 3, 4, 5, 7, 8, 3, 4, 4, 7, 6, 7, 8, 7, 2, 3, 4, 10, 9, 10, 5, 10, 4, 1, 2, 4, 6, 7, 9, 10, 8, 9, 5, 4, 10, 1, 7, 2, 9, 7, 10, 3, 2, 9, 3, 7, 10, 4, 6, 3, 4, 5, 6, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 8, 4, 6, 7, 8, 9, 1, 3, 4, 5, 6, 1, 6, 4, 10, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 4, 6, 8, 9, 10, 6, 10, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 9, 10, 3, 6, 7, 6, 7, 9, 1, 3, 7, 2, 3, 7, 9, 8, 4, 5, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 8, 9, 5, 2, 6, 8, 9, 1, 1, 4, 5, 5, 5, 7, 6, 8, 4, 10, 2, 1, 2, 3, 5, 8, 9, 5, 9, 5, 9, 2, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 7, 10, 1, 3, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 10, 8, 2, 3, 9, 10, 3, 6, 7, 10, 9, 1, 1, 8, 3, 4, 6, 8, 4, 10, 1, 2, 3, 4, 7, 8, 9, 6, 4, 6, 7, 8, 1, 3, 4, 5, 6, 8, 1, 4, 8, 1, 2, 3, 4, 8, 1, 1, 3, 4, 5, 6, 7, 8, 1, 3, 4, 6, 8, 5, 2, 8, 9, 10, 1, 1, 2, 3, 4, 6, 7, 8, 5, 10, 1, 2, 5, 6, 7, 8, 6, 1, 3, 2, 3, 1, 2, 3, 5, 6, 7, 8, 9, 6, 10, 1, 2, 3, 5, 7, 10, 1, 2, 3, 4, 5, 6, 8, 3, 6, 7, 8, 9, 1, 3, 4, 6, 8, 1, 3, 4, 6, 7, 8, 1, 2, 1, 2, 3, 5, 7, 8, 8, 1, 3, 4, 10, 1, 2, 5, 6, 7, 3, 4, 5, 5, 1, 2, 3, 4, 5, 9, 4, 4, 1, 2, 3, 4, 5, 7, 8, 9, 8, 3, 4, 6, 5, 4, 7, 8, 9, 1, 10, 5, 2, 5, 9, 1, 2, 3, 4, 5, 7, 8, 10, 1, 3, 8, 3, 4, 6, 7, 9, 3, 8, 2, 8, 9, 10, 2, 3, 5, 6, 9, 10, 3, 4, 5, 7, 8, 9, 10, 6, 7, 5, 9, 10, 2, 3, 5, 3, 10, 4, 9, 1, 10, 3, 4, 6, 1, 2, 3, 7, 7, 10, 2, 4, 6, 7, 8, 9, 3, 1, 3, 4, 6, 7, 3, 4, 4, 6, 7, 10, 4, 7, 2, 4, 6, 7, 8, 9, 10, 10, 1, 10, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 5, 7, 1, 2, 3, 4, 6, 7, 8, 9, 2, 2, 3, 6, 6, 1, 3, 4, 1, 2, 7, 8, 9, 10, 1, 3, 4, 6, 7, 6, 6, 3, 7, 1, 3, 4, 6, 7, 8, 1, 2, 5, 6, 7, 8, 8, 1, 9, 9, 4, 4, 7, 9, 10, 2, 6, 9, 3, 4, 5, 4, 8, 1, 2, 3, 5, 7, 8, 4, 3, 1, 2, 4, 6, 7, 9, 1, 2, 5, 6, 7, 9, 10, 9, 4, 1, 2, 3, 5, 7, 8, 10, 1, 2, 5, 8, 1, 2, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 2, 3, 1, 7, 3, 5, 9, 2, 1, 3, 5, 8, 9, 10, 3, 4, 10, 3, 1, 2, 5, 7, 8, 2, 3, 8, 2, 2, 9, 3, 3, 3, 1, 2, 3, 5, 7, 8, 6, 3, 4, 5, 6, 1, 6, 6, 7, 8, 9, 6, 1, 2, 3, 6, 7, 8, 3, 4, 1, 1, 9, 1, 2, 3, 5, 6, 7, 8, 9, 2, 3, 5, 10, 2, 2, 4, 5, 7, 8, 10, 7, 5, 2, 3, 7, 5, 8, 10, 2, 3, 4, 1, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 9, 10, 3, 7, 7, 7, 7, 1, 2, 3, 4, 5, 6, 8, 9, 4, 1], \"Freq\": [0.9940274878697413, 0.5918889921094487, 0.2412795891401574, 0.0025133290535433064, 0.04900991654409447, 0.007539987160629919, 0.08293985876692911, 0.02387662600866141, 0.09918768638284131, 0.020467300364713285, 0.020467300364713285, 0.8438825381143323, 0.015744077203625605, 0.19172486954088538, 0.14379365215566403, 0.10917666182189306, 0.5512089999300455, 0.02983725753326837, 0.13426765889970765, 0.8329567728037419, 0.7754063069780316, 0.09370468966501892, 0.07027851724876419, 0.0609080482822623, 0.9974145227823944, 0.9913403325140936, 0.9721327718093081, 0.01786576738271393, 0.9800649535660214, 0.9894246564565098, 0.9899862579237078, 0.9829996055796036, 0.06659867062338579, 0.19979601187015736, 0.07325853768572436, 0.6593268391715192, 0.9984192209451932, 0.9880558458540544, 0.1257082088400124, 0.07956215749367873, 0.0318248629974715, 0.012729945198988598, 0.058875996545322266, 0.13366442458938027, 0.03341610614734507, 0.523518996308406, 0.09299688378230248, 0.05072557297216499, 0.8130182112483111, 0.04227131081013749, 0.12815642158467652, 0.5286452390367906, 0.17265517907935587, 0.03203910539616913, 0.13883612338339957, 0.45350861482045385, 0.5451113482775654, 0.1732602887221694, 0.8229863714303046, 0.9842280917986598, 0.9822148311048466, 0.9954847237340182, 0.9970965630615974, 0.9893625395643787, 0.14287720293690037, 0.8541571914706, 0.9978707094515977, 0.9995536706402389, 0.9253143322783458, 0.0722364348618783, 0.990921260339764, 0.08624008728295926, 0.27066119701113367, 0.12604320449047893, 0.042456658354687635, 0.005307082294335954, 0.042456658354687635, 0.42589335412046037, 0.2729230713730128, 0.5039867759710237, 0.22269183124301048, 0.9733975647704375, 0.9793639378699606, 0.9833181609411327, 0.03468666745805259, 0.1329655585892016, 0.5913250928563252, 0.16269698783896097, 0.06606984277724304, 0.012388095520733068, 0.972371490745196, 0.9976391471527591, 0.9953610099802569, 0.9947119801159755, 0.9888460361333021, 0.9954599369841461, 0.9859390946218568, 0.9969838894717836, 0.9938443134551423, 0.9887798657646407, 0.6026123556241715, 0.17003170200184092, 0.028755361367958393, 0.028755361367958393, 0.07126328686841862, 0.0987684151334223, 0.9924588569266201, 0.19211680732955314, 0.16128324565937793, 0.018974499489338582, 0.2608993679784055, 0.055737592249932084, 0.01778859327125492, 0.29054702343049704, 0.32874699827799336, 0.3406294199024992, 0.03069625586330661, 0.25646226672891653, 0.036637466675559505, 0.006931412614295041, 0.9980171657832464, 0.9931937674898901, 0.9828286516479237, 0.9857086763325393, 0.013397926972855485, 0.9780486690184503, 0.24390913628341035, 0.05105074945466728, 0.07090381868703789, 0.022689221979852126, 0.028361527474815157, 0.5842474659811923, 0.24450439890174608, 0.050689936357679065, 0.7007138261208576, 0.13836098765610463, 0.41769354764107064, 0.0026105846727566915, 0.43857822502312416, 0.027271959957177128, 0.004545326659529521, 0.14317778977517992, 0.1386324631156504, 0.19431271469488703, 0.0011363316648823802, 0.2068123630085932, 0.28408291622059506, 0.06371423580909619, 0.9318206987080319, 0.9946354598461338, 0.14521716763075626, 0.8489619030721135, 0.9923792631554735, 0.9950990946313567, 0.15927484191403038, 0.840617221212938, 0.07730001001241772, 0.9069867841457012, 0.015460002002483543, 0.039267241397144055, 0.9502672418108862, 0.9948062677192431, 0.9884054743787797, 0.9897063808243479, 0.9904220932288661, 0.9870712216948602, 0.997152608608289, 0.996365391846328, 0.05423530137986566, 0.9374959238519635, 0.9981682803469616, 0.013953321424073956, 0.08837103568580172, 0.0325577499895059, 0.7023171783450558, 0.16278874994752948, 0.4865016373513936, 0.03396171988491404, 0.04754640783887965, 0.12735644956842765, 0.049244493833125354, 0.06282918178709097, 0.0849042997122851, 0.10867750363172492, 0.9827309503179702, 0.29186481962751265, 0.17325308927660568, 0.0519759267829817, 0.4384635874769482, 0.04397963035483067, 0.9941836135173575, 0.9883121733915179, 0.05737197140125068, 0.1366802848088619, 0.6817140131207434, 0.11811876464963375, 0.00506223277069859, 0.8023903978241619, 0.09761037829201145, 0.03474267701919052, 0.006617652765560098, 0.01819854510529027, 0.03970591659336059, 0.02835110075726817, 0.07087775189317042, 0.12757995340770675, 0.7654797204462405, 0.9907792547188549, 0.9941581233623085, 0.7854142984625926, 0.19138831180927543, 0.021666601336899106, 0.9984974145151633, 0.9907798429451755, 0.9878612748256725, 0.9929426607624275, 0.9892436169269188, 0.11611100345301342, 0.8761102987818286, 0.6907729273815462, 0.2273649585100064, 0.039919038517024025, 0.039919038517024025, 0.9938611674540356, 0.6452498574757743, 0.044639927246751684, 0.0872507668913783, 0.022319963623375842, 0.06493080326800245, 0.13391978174025507, 0.9863083936674564, 0.9865834624474752, 0.020638764247478857, 0.975181610693376, 0.9932084477371659, 0.09426270832119615, 0.9038130268444101, 0.013921901864057638, 0.9849745568820779, 0.9925098661934627, 0.9968803483859252, 0.9823188080584454, 0.30846028972565565, 0.5151943136907227, 0.1755598457481125, 0.010182118213341678, 0.004072847285336672, 0.0285099309973567, 0.8064237624966609, 0.14865892591478852, 0.9928030535293672, 0.2352539342013525, 0.46620444277707046, 0.08606851251268993, 0.0028689504170896643, 0.08463403730414511, 0.0028689504170896643, 0.02008265291962765, 0.02582055375380698, 0.0753099484486037, 0.9936021978195148, 0.005436096026613571, 0.12503020861211211, 0.16308288079840713, 0.7039744354464574, 0.2612641948293724, 0.7365761637358209, 0.7501177266127942, 0.20171232984545726, 0.047276327307529044, 0.044374348317032346, 0.10169121489319913, 0.08689976545418834, 0.14051876967060242, 0.5805643904811733, 0.042525417137156, 0.05654726114478038, 0.02261890445791215, 0.9160656305454421, 0.9799613656819648, 0.9934720576129646, 0.20427271238744918, 0.05075098444408675, 0.04948220983298458, 0.23091697922059473, 0.01141897149991952, 0.05836363211069977, 0.10530829272148001, 0.2880118367201923, 0.006342833146525263, 0.39325565508456634, 0.13161378779039923, 0.03329987401925764, 0.43448407053698057, 0.9755259618890932, 0.9820901236372401, 0.9957339090390092, 0.18887095889817518, 0.1577169862964143, 0.09930328766811272, 0.025312602738930694, 0.03504821917698096, 0.4926221917653435, 0.990135934468267, 0.9773119770463304, 0.9970256643922454, 0.98510013047952, 0.9977436525006725, 0.9837234415316458, 0.9891420836773089, 0.2658947016893049, 0.3186051051078896, 0.10073543764440626, 0.3150910782133173, 0.8599653840773366, 0.13423849897792572, 0.9936239887820784, 0.9947193401311384, 0.09828567385669115, 0.09828567385669115, 0.052923055153602926, 0.7283220447329165, 0.02268130935154411, 0.30681567407198246, 0.004351995376907552, 0.6876152695513933, 0.9750165765075791, 0.9834876877699509, 0.985104576396779, 0.9944236618442965, 0.9945605316979975, 0.012215902621533551, 0.5411644861339363, 0.02321021498091375, 0.062301103369821115, 0.09039767939934829, 0.26874985767373816, 0.010843008735237039, 0.1445734498031605, 0.838526008858331, 0.9938445006473274, 0.9950936291968512, 0.4950543869961265, 0.21162630283803882, 0.015116164488431345, 0.08597318552795327, 0.014171404207904387, 0.012281883646850468, 0.11620551450481596, 0.05007229486792883, 0.9987621789672328, 0.14102263831841472, 0.06410119923564306, 0.7948548705219739, 0.9984869365223449, 0.12508200700648078, 0.8677564236074604, 0.023318655004999484, 0.7398373269768018, 0.12083303048045187, 0.06571620955954399, 0.04875718773772619, 0.9801191528489299, 0.07129269903730155, 0.11882116506216925, 0.8079839224227509, 0.9772539741012183, 0.7335402256527361, 0.0661624517255409, 0.19848735517662272, 0.9778845803857302, 0.3215041598767719, 0.027737613793290122, 0.6505731235153501, 0.746097263408642, 0.25362382221481894, 0.7799705629924893, 0.21839175763789703, 0.9861378327267154, 0.9975575699500688, 0.23762535507973626, 0.11576619862858946, 0.017060281903160553, 0.4642833860788693, 0.0304647891127867, 0.13526366366077294, 0.719007074790557, 0.2692637830693382, 0.010188359359380363, 0.9988781159309582, 0.06334372234713549, 0.016669400617667234, 0.9168170339716978, 0.7447904424007233, 0.22799707420430307, 0.02431968791512566, 0.9822248913832647, 0.9976681478710904, 0.15706585418793045, 0.026177642364655074, 0.09598468867040194, 0.7198851650280146, 0.9920627241363945, 0.9962677616612933, 0.9938141247300304, 0.15783839348850448, 0.025162642440196368, 0.2150262172162235, 0.03202518128752265, 0.5558656466334289, 0.013725077694652565, 0.7385934498802527, 0.0897897919462268, 0.1593044695820153, 0.011585779605964748, 0.007047527542707741, 0.0951416218265545, 0.12685549576873933, 0.021142582628123224, 0.7470379195270205, 0.9868761180772577, 0.6641394907661966, 0.3320697453830983, 0.5907315477935713, 0.04062004749071708, 0.22515112037711751, 0.029014319636226485, 0.017408591781735892, 0.09864868676317005, 0.9966515998778364, 0.021395005231186, 0.5958184790139374, 0.3766817587672444, 0.00583500142668709, 0.9870882949459249, 0.041122271749759416, 0.9458122502444666, 0.08882667368504547, 0.9044170411568266, 0.011982286437718337, 0.9825474878929037, 0.9964703276226179, 0.9864680965445856, 0.343809190095727, 0.37892161802039703, 0.004389053490583749, 0.04827958839642124, 0.22237871018957664, 0.9944162705304119, 0.9844190568534383, 0.9813965595601486, 0.016332212510324157, 0.0832942838026532, 0.2580489576631217, 0.5993921991288966, 0.042463752526842806, 0.9952816424265769, 0.9530866970148996, 0.046635596100966584, 0.09010967485681493, 0.9010967485681493, 0.9908370783700595, 0.9915004742741365, 0.9926725010431979, 0.9569608990547958, 0.03728419087226477, 0.9850354531870473, 0.9966639744020053, 0.2536381663282649, 0.46408031306350656, 0.033227707379248676, 0.14509432222271923, 0.07753131721824692, 0.012183492705724516, 0.014398673197674428, 0.18511427890856494, 0.6660571183695734, 0.028342856100832908, 0.08148571128989461, 0.007085714025208227, 0.030999998860285993, 0.06406054934258143, 0.007764915071828051, 0.06406054934258143, 0.8444345140613005, 0.017471058911613116, 0.0019412287679570128, 0.9913744517672957, 0.279768294835092, 0.3829739587525582, 0.025801415979366537, 0.1578439565796541, 0.0020236404689699243, 0.0010118202344849621, 0.017706854103486838, 0.13254845071753005, 0.44659103396962263, 0.5526273799901397, 0.8081673353033222, 0.18619541548654972, 0.1225256914604299, 0.32854234081867484, 0.08891244867040045, 0.028191752017444047, 0.19517366781307416, 0.0010842981545170786, 0.04228762802616607, 0.0043371926180683145, 0.18975217704048877, 0.9960058612270893, 0.9971759916171569, 0.05263969274838619, 0.026319846374193094, 0.010527938549677238, 0.04737572347354757, 0.8632909610735335, 0.22319181736499605, 0.0041718096703737585, 0.23883610362889765, 0.12619724252880618, 0.379634680004012, 0.01981609593427535, 0.008343619340747517, 0.9762350671919791, 0.28152536992344307, 0.4988244197122604, 0.16270667767438537, 0.01391570269583559, 0.03425403740513376, 0.00856350935128344, 0.2814295811969519, 0.25674277582879823, 0.013166296196348628, 0.06253990693265599, 0.024686805368153677, 0.36207314539958724, 0.975141219183125, 0.07027042198158963, 0.9213233104252864, 0.01191651731627848, 0.9866876337878582, 0.11185951567925012, 0.7545777498362974, 0.1270269076357586, 0.005687771983690685, 0.9858696444256695, 0.9883812936978175, 0.12689901524548447, 0.28701320897804206, 0.09538717924492793, 0.11667896032638504, 0.009368383675841136, 0.11667896032638504, 0.2103627970847964, 0.022995123567973695, 0.01533008237864913, 0.09087251427467354, 0.2233493121931735, 0.01313819483489256, 0.3547312605420991, 0.07444977073105784, 0.01313819483489256, 0.09087251427467354, 0.0985364612616942, 0.04050943407425206, 0.07896189282984536, 0.7597414553358095, 0.0661572615601407, 0.08109599804146281, 0.010670526058087212, 0.9913728092831585, 0.999186611671697, 0.04104926362590661, 0.26682021356839297, 0.05473235150120881, 0.6431051301392036, 0.9958847672716316, 0.9921838062051495, 0.9803131140347084, 0.5145485512212971, 0.26450108110532966, 0.05492372175957665, 0.06359588835319402, 0.10117527692553593, 0.8429730570986887, 0.042790510512623794, 0.08558102102524759, 0.025674306307574276, 0.9952135265864797, 0.9884412229596092, 0.9915062033591797, 0.008818821273243859, 0.08248191661445727, 0.10790087204910133, 0.015562625776312691, 0.287389822669241, 0.24537073307319676, 0.006743804503068833, 0.24537073307319676, 0.2024758383367658, 0.030991199745423335, 0.05371807955873378, 0.6280883148405796, 0.01652863986422578, 0.06818063943993134, 0.18573797382095797, 0.03910273133072799, 0.7722789437818778, 0.9969105520974462, 0.9891708116121565, 0.09371098923114836, 0.0019124691679826195, 0.8988605089518311, 0.003824938335965239, 0.003822325311272914, 0.06561658451018501, 0.19876091618619152, 0.5790822846578464, 0.016563409682182624, 0.13569254855018845, 0.9960244137668876, 0.8990246177049378, 0.09816935480686102, 0.986433977479974, 0.28180472379594745, 0.028072501221052235, 0.008637692683400687, 0.07557981097975602, 0.12416683232388488, 0.06262327195465499, 0.41784838355950826, 0.16251305802230756, 0.8345265141686063, 0.9982442975638577, 0.9748401002770823, 0.9819058113274399, 0.006481500814565672, 0.9851881238139821, 0.9985054462190841, 0.9994020764121773, 0.2789163384398861, 0.11322346411916168, 0.08560798506570762, 0.13117352550390682, 0.2402546677650504, 0.14912358688865196, 0.9917023949926452, 0.976019929341502, 0.03468449653457855, 0.03902005860140087, 0.1344024240714919, 0.15608023440560348, 0.6373276238228809, 0.9839807272576765, 0.016875008509568887, 0.9821254952569093, 0.15818359189359277, 0.8397687746115734, 0.9897904018286969, 0.13094294140442564, 0.8677412833367908, 0.9920878082737039, 0.015827268608430936, 0.06670063199267323, 0.8874575612584489, 0.023740902912646404, 0.005652595931582477, 0.0011305191863164954, 0.0411103322613163, 0.04484763519416324, 0.8969527038832648, 0.014949211731387746, 0.3025132009899577, 0.532205451460398, 0.008166835572282323, 0.0034028481551176344, 0.018715664853146987, 0.011569683727399957, 0.06125126679211742, 0.05104272232676452, 0.0030625633396058707, 0.008166835572282323, 0.9848314642811092, 0.9976846897688487, 0.9975780707417121, 0.9842452304714991, 0.014753140499572793, 0.9861907283695885, 0.9860236151391831, 0.9855614696998113, 0.02397648007916703, 0.47195808155834046, 0.18802608062083617, 0.176668800583336, 0.012619200041666858, 0.1261920004166686, 0.20551319134995838, 0.09096485518768649, 0.7007662918162515, 0.9816525398151768, 0.2964574217447554, 0.500074085078342, 0.02426519822110098, 0.004220034473234953, 0.028221480539758745, 0.025056454684832533, 0.06541053433514177, 0.035606540867919916, 0.020572668057020394, 0.010995228380180086, 0.2244859127620101, 0.05680867996426378, 0.13835662378393274, 0.31977789205690416, 0.1924164966531515, 0.055892410932582105, 0.9848140413797055, 0.05766681720802659, 0.04767123555863532, 0.002306672688321064, 0.046902344662528295, 0.724295224132814, 0.01307114523381936, 0.07842687140291617, 0.029217854052066807, 0.9762036567751116, 0.21548807203512038, 0.6023871104618137, 0.031833465187006416, 0.026936009004390048, 0.05142328991747191, 0.028160373050044138, 0.028160373050044138, 0.015916732593503208, 0.18944522715987325, 0.31691146024892375, 0.486476632706835, 0.005847074912341766, 0.8812004933528204, 0.01246981830216255, 0.0997585464173004, 0.9929855072873136, 0.9906621685161491, 0.10781285502089383, 0.5365686071641707, 0.019466209934328054, 0.002994801528358162, 0.059396896979103546, 0.05091162598208875, 0.1512374771820872, 0.004492202292537243, 0.03444021757611886, 0.03244368322388009, 0.007884129212085702, 0.123518024322676, 0.123518024322676, 0.04467673220181898, 0.6596388107445037, 0.036792602989733275, 0.9965738183599927, 0.9942704703987376, 0.9951553663898541, 0.016457143822824805, 0.7928050154647776, 0.19033044595093035, 0.5156886280129769, 0.2073668557089219, 0.01909957881529544, 0.01773532318563148, 0.068212781483198, 0.07912682652050967, 0.09276938281714928, 0.9900318027934517, 0.13295170297292838, 0.009694395008442696, 0.1468008386992751, 0.15788014728035246, 0.031853012170597425, 0.48056500970423077, 0.040162493606405454, 0.05980535238735077, 0.022427007145256538, 0.18689172621047115, 0.7301236770622406, 0.993903929712574, 0.9814139330587727, 0.11618261272311678, 0.8713695954233758, 0.989459870076929, 0.007118416331488698, 0.9877710966595119, 0.3234094048129716, 0.5851453882430043, 0.04211843411517769, 0.024067676637244396, 0.024067676637244396, 0.9879232646887766, 0.6102090620931083, 0.19576672981826684, 0.014578373497104977, 0.0010413123926503556, 0.006247874355902133, 0.02499149742360853, 0.14578373497104977, 0.02755753642555376, 0.9700252821794922, 0.9970819885079826, 0.9939566044866235, 0.5647978847401979, 0.08280406625293929, 0.35099037038559344, 0.9888556890714938, 0.7653011614299997, 0.054311695327290306, 0.02468713423967741, 0.15306023228599994, 0.9809738041736723, 0.9841818464127683, 0.9927500040673232, 0.9910110349661551, 0.9965367638151215, 0.002551377487187588, 0.14287713928250495, 0.15308264923125528, 0.01275688743593794, 0.05102754974375176, 0.520481007386268, 0.11226060943625388, 0.2724426209524516, 0.7222897392692903, 0.994794263403678, 0.5772837853343085, 0.41731357975974104, 0.9944080610779107, 0.9988728393390873, 0.9336947381465481, 0.06224631587643654, 0.9807461486234885, 0.012573668572096006, 0.9945523052055423, 0.06378451703278816, 0.9248754969754283, 0.9983178607239948, 0.9893539712038611, 0.9857517854229053, 0.9474524759061963, 0.05203400325342955, 0.5178386283021448, 0.27774980972569585, 0.08591413605921948, 0.0011769059734139653, 0.11769059734139654, 0.9977586544281248, 0.129875465063323, 0.3432003239682382, 0.0005876717876168462, 0.07110828630163839, 0.019393168991355923, 0.08815076814252693, 0.13340149578902408, 0.15573302371846426, 0.05817950697406778, 0.9947908073812927, 0.9859324046402399, 0.039580177869307405, 0.7102443028770162, 0.0505746717218928, 0.06816586188602942, 0.1297350274605076, 0.06892045602308748, 0.14741319760493712, 0.13592645493442254, 0.09189394136411665, 0.5532781052964524, 0.24461867383406324, 0.7526728425663485, 0.9962364117033261, 0.9883167668641443, 0.9862372637373654, 0.9944239009581869, 0.1413662739900268, 0.03148612466141506, 0.09831381782033681, 0.15614547536171142, 0.09124550412083547, 0.27630680825323417, 0.0192772191804582, 0.16963952878803215, 0.015421775344366558, 0.019748365054508627, 0.05078151014016504, 0.04796031513237809, 0.015516572542828207, 0.8590538798711252, 0.007052987519467367, 0.990558598242712, 0.9752586217933192, 0.9927738700023323, 0.8211995412290438, 0.1581363981420794, 0.019420259420957115, 0.9981552780051883, 0.18964036117901573, 0.009403654273339623, 0.032912789956688684, 0.02037458425890252, 0.17866943119345285, 0.43256809657362266, 0.13635298696342454, 0.9960880482581826, 0.8902501002573574, 0.10692948131582784, 0.20637912364194905, 0.2123323675931591, 0.57944907791778, 0.9084120987739396, 0.08854558363500495, 0.9912626364709947, 0.9691559517181827, 0.020403283194067003, 0.8773764515600869, 0.1200184768643515, 0.9949418762327278, 0.9983920155911615, 0.9899035206926142, 0.9968578845590841, 0.43100040253240934, 0.15169103685149832, 0.35350606848870914, 0.00032976312359021375, 0.0009892893707706412, 0.008903604336935772, 0.05342162602161463, 0.05702498864864871, 0.007128123581081089, 0.05880701954391898, 0.17107496594594612, 0.6842998637837845, 0.0035640617905405444, 0.017820308952702722, 0.3681612369343199, 0.22228602984713655, 0.11808945335629129, 0.06747968763216645, 0.10518892483837711, 0.11610475666122756, 0.0029770450425955788, 0.9969699118927897, 0.06206796615584058, 0.0805206047427121, 0.7146203670915698, 0.14258857089855267, 0.9913203600773576, 0.991979667170305, 0.9919137929434244, 0.9979140567217553, 0.9939355364286495, 0.9973626608221964, 0.9905782321738632, 0.9943405321030611, 0.9884257583037702, 0.22184106174642887, 0.7739788154264295, 0.9897462243799279, 0.02617800565650002, 0.007600066158338716, 0.009288969749080653, 0.9263636195219523, 0.01688903590741937, 0.012666776930564528, 0.9788955028981462, 0.0195090545712409, 0.9909751669377389, 0.0063321096928929, 0.22135451335362835, 0.07747407967376992, 0.0848525634522242, 0.02951393511381711, 0.582900218497888, 0.4797818246375064, 0.147984653703127, 0.018692798362500252, 0.024144864551562825, 0.2461218451062533, 0.014019598771875188, 0.024923731150000333, 0.043616529512500585, 0.9915356211418195, 0.9889909336069519, 0.1145542643568833, 0.8823774416678849, 0.4000185523108757, 0.02772405808095178, 0.013201932419500847, 0.006600966209750423, 0.05808850264580373, 0.47857005020690574, 0.0006600966209750423, 0.0019802898629251273, 0.01386202904047589, 0.06254234731267594, 0.17753956656501557, 0.12811093723725556, 0.11903220940154453, 0.21889821559436579, 0.03328866873094042, 0.1785483141023168, 0.08170855052139922, 0.9694682354951814, 0.013817641206411007, 0.015073790406993826, 0.9169889164254578, 0.054014415625061214, 0.09082080307632467, 0.40324436565888155, 0.09082080307632467, 0.40687719778193454, 0.9914667468533368, 0.9929222738977711, 0.9884993797013946, 0.9987108935568051, 0.009396381486796607, 0.06577467040757626, 0.02192489013585875, 0.8989204955702088, 0.9846574710805154, 0.008791584563218888, 0.2608505367561093, 0.32041976990954774, 0.0056434010355889035, 0.1348145802946238, 0.25959644763708956, 0.018184292225786467, 0.9824037926905166, 0.9754995513541961, 0.216486137024393, 0.3589439685720539, 0.37574030678946374, 0.047900668249650176, 0.04786417360874874, 0.005983021701093593, 0.7209541149817779, 0.014957554252733981, 0.17949065103280776, 0.03290661935601476, 0.2828670836911857, 0.1208613903044157, 0.5940208757514899, 0.018815696725242463, 0.12125671222934033, 0.1965194991303102, 0.1275286111377545, 0.5352020401846745, 0.989970770654518, 0.08973752120274203, 0.02437315390691759, 0.3367926721683158, 0.0033236118963978533, 0.26367321044756303, 0.05982501413516136, 0.22268199705865616, 0.05187803871242853, 0.12450729290982847, 0.1433720342598025, 0.16695296094727, 0.5121777276517944, 0.9906097851014711, 0.03947273135343361, 0.15789092541373445, 0.7006409815234467, 0.09868182838358404, 0.9877903064548765, 0.4891028721399789, 0.15042995899431283, 0.029592778818553343, 0.03288086535394816, 0.13152346141579263, 0.06904981724329114, 0.09699855279414707, 0.9603855179597879, 0.034299482784278135, 0.5147765337093764, 0.13782137693282948, 0.0018254487010970792, 0.26103916425688234, 0.04472349317687844, 0.0392471470735872, 0.9924231649421036, 0.956414341682444, 0.03336329098892246, 0.9636421665941174, 0.03125325945710651, 0.6714178937334585, 0.17376665243637746, 0.0010282050440022334, 0.015423075660033501, 0.0010282050440022334, 0.015423075660033501, 0.07917178838817197, 0.04215640680409157, 0.9822791829099575, 0.9779681149094327, 0.22180424224498269, 0.6618061536903143, 0.054098595669507976, 0.041475590013289446, 0.019836151745486256, 0.9725041803477417, 0.031001877209606597, 0.008857679202744741, 0.394166724522141, 0.4262758116320907, 0.05203886531612536, 0.08193353262538887, 0.005536049501715464, 0.009727866569116821, 0.8824564673413116, 0.041690856724786375, 0.044470247173105465, 0.020845428362393188, 0.12139258635088769, 0.0394891545960719, 0.7502939373253661, 0.08190343175481579, 0.004387683844007988, 0.02790743229514767, 0.005581486459029533, 0.14790939116428264, 0.05581486459029534, 0.7535006719689871, 0.005581486459029533, 0.9910878528846427, 0.9969097795917157, 0.47483844594418856, 0.2364024382912716, 0.1367575395706496, 0.05490637276442437, 0.013726593191106093, 0.08235955914663656, 0.991474776207395, 0.030338231472678955, 0.007584557868169739, 0.811547691894162, 0.15169115736339478, 0.007032988228815569, 0.20044016452124375, 0.2637370585805839, 0.0726742116977609, 0.45597207016820945, 0.8913896404746422, 0.09289426408494054, 0.013835315927544336, 0.9924991077124363, 0.06081289338044745, 0.32456319500800607, 0.5220342757602455, 0.033481255906089046, 0.05876302056987057, 0.9990496734239936, 0.9973024326354836, 0.9889801933035604, 0.2650321926751217, 0.47208859320256047, 0.15972922326402422, 0.014198153179024375, 0.004732717726341458, 0.011831794315853645, 0.05442625385292677, 0.01774769147378047, 0.9961537296974092, 0.059571397841260885, 0.8883908460674993, 0.0518012155141399, 0.9979730718986086, 0.02386257086222972, 0.9272313249323549, 0.006817877389208492, 0.03749832564064671, 0.01214224574180447, 0.983521905086162, 0.9986359110046567, 0.8390234553493526, 0.0468728187346007, 0.10780748308958163, 0.13155300720968655, 0.20126485718405035, 0.1259310838246572, 0.050597310465264056, 0.3159520942386489, 0.05846800320430513, 0.07420938868238729, 0.04160223304921711, 0.0902299765774071, 0.09645273358274552, 0.8089584106939947, 0.13803545553645077, 0.07177843687895441, 0.7702378418933954, 0.013803545553645078, 0.005521418221458031, 0.07038066666125443, 0.9287940436444232, 0.05013389606883969, 0.07779397665854434, 0.8626487633914139, 0.006915020147426164, 0.007015715291698761, 0.028062861166795044, 0.022049390916767535, 0.8188341990454125, 0.10323123929213891, 0.02004490083342503, 0.9919715093765693, 0.11373186151182298, 0.6333303660658378, 0.02230036500231823, 0.006690109500695469, 0.06244102200649105, 0.15833259151645945, 0.14960165754892954, 0.8501173555955045, 0.9900261587780299, 0.9261164547892236, 0.07286703070676633, 0.9929762998780046, 0.3264421891270701, 0.6719621685278002, 0.9961224108584951, 0.9751018239402067, 0.9982100830690847, 0.9773866336435568, 0.9925493812455763, 0.986738788019919, 0.04586559892990018, 0.17035793888248638, 0.7818992579478221, 0.798417923926919, 0.05443758572228993, 0.13004534366991483, 0.015121551589524981, 0.01830809197940809, 0.9520207829292208, 0.9845789515397232, 0.004005246485606821, 0.5540590971756102, 0.21227806373716152, 0.0333770540467235, 0.19625707779473422, 0.995722217969114, 0.06232870676881439, 0.18896480941021504, 0.1276254471932866, 0.4125566781364381, 0.2087517004479339, 0.8118678649574522, 0.1858822047714032, 0.8857038774718392, 0.05244299274504311, 0.027678246170994975, 0.03350524536488865, 0.9933945629988835, 0.9913468589855009, 0.792049801020001, 0.006061605620051028, 0.028287492893571464, 0.018184816860153084, 0.014143746446785732, 0.09092408430076541, 0.0505133801670919, 0.9790452525385981, 0.23881114455112426, 0.7531736097381612, 0.01137605703574844, 0.2701813545990255, 0.7195356075110888, 0.12098859536471751, 0.47192627548693905, 0.08065906357647834, 0.02264114065304655, 0.13089409440042538, 0.023348676298454257, 0.14150712908154095, 0.0077828920994847525, 0.8888286307482309, 0.10748625302071631, 0.3768586979988358, 0.002849593179575318, 0.3362519951898875, 0.13820526920940293, 0.001424796589787659, 0.022796745436602543, 0.0869125919770472, 0.03490751644979764, 0.9923714512242128, 0.9910668868672573, 0.05052782652016074, 0.9448703559270059, 0.9961190573356402, 0.0678418294587534, 0.11373483173967483, 0.8180926493555558, 0.052555002173340915, 0.6706018277318301, 0.12402980512908456, 0.029430801217070913, 0.06096380252107546, 0.0630660026080091, 0.2352565614768869, 0.0887032936716131, 0.04113775938393651, 0.38180982928216073, 0.2519687762266111, 0.9923672735228016, 0.9837483906593772, 0.9907955032987839, 0.9937699788673368, 0.19645601015671257, 0.12829780255132248, 0.1002326582432207, 0.05111865570404255, 0.4871307190620526, 0.037086083549991655, 0.4145324955437112, 0.37476918661865494, 0.049704136156320286, 0.0516923016025731, 0.05368046704882591, 0.055668632495078724, 0.9918119754959125, 0.9923053980542027, 0.9836769204403287, 0.9837138294697457, 0.9891475553541277, 0.9897761760178163, 0.014039241198920999, 0.042117723596762996, 0.9265899191287859, 0.08930660179407798, 0.08930660179407798, 0.8149227413709617, 0.9928300572692951, 0.01791746745609839, 0.981325909903235, 0.3835426160980707, 0.6157794295152512, 0.39175633008075783, 0.4943889788559085, 0.008761323675927492, 0.016271029683865342, 0.07384544241138886, 0.015019412015875701, 0.9924526790710269, 0.9920942058418404, 0.008211726649625273, 0.10127796201204503, 0.5447112010918098, 0.22992834618950767, 0.07938002427971097, 0.03421552770677197, 0.03953183287778838, 0.26542802075086486, 0.016942214090480735, 0.28707640542203466, 0.22683742198921428, 0.15906856562729135, 0.005647404696826911, 0.987322960008331, 0.9931297976351666, 0.39538030332680946, 0.5062164211446528, 0.0006481644316832943, 0.0012963288633665885, 0.060927456578229656, 0.023982083972281888, 0.011018795338616001, 0.4946605422796111, 0.38451665457329703, 0.09790567796116803, 0.022502514692687815, 0.9827085684947089, 0.11401728035334384, 0.14116425186604475, 0.7383976251454648, 0.30244328892930605, 0.34613994574055773, 0.07147524578411876, 0.0586783677179665, 0.0839600048730478, 0.03246037363121551, 0.05899048669518973, 0.03651792033511745, 0.009675688293920008, 0.9949294518530063, 0.6800508047399967, 0.31883687581281744, 0.986106160987895, 0.9971500571353497, 0.032191380925573984, 0.9657414277672195, 0.979464318935027, 0.9881720092449371, 0.028964954525672274, 0.019309969683781517, 0.458611779989811, 0.05068867041992648, 0.4175780944117753, 0.024137462104726896, 0.10282861772684548, 0.8960779544767963, 0.9718297730477028, 0.995359492893872, 0.6686721986024099, 0.15388620460986968, 0.04579946565769931, 0.1062547603258624, 0.02381572214200364, 0.10543709090954397, 0.0871002055339711, 0.806822956525206, 0.9874828084464228, 0.11295762843606201, 0.8831232768637575, 0.9976721451096039, 0.9978834256859196, 0.9986855428491512, 0.12875906459775896, 0.7169177547356702, 0.08107052215414452, 0.03179236162907628, 0.01589618081453814, 0.027023507384714842, 0.97267403232477, 0.3630088901117686, 0.31197888638998644, 0.01855636498973897, 0.306180022330693, 0.06630535682380316, 0.9330110924492302, 0.5447651234166201, 0.34379608716779736, 0.10996418964558224, 0.9948020385462373, 0.9935984161154877, 0.9908588984083907, 0.9926303710271974, 0.011686646842929468, 0.30904688317969037, 0.6531537068881691, 0.024671810001739986, 0.9980267743813599, 0.9947497360300841, 0.9838150139826896, 0.996388910811058, 0.9807284914587069, 0.31151635716859793, 0.4122399793197779, 0.028036472145173814, 0.0010383878572286598, 0.026478890359330823, 0.09657007072226535, 0.05140019893281866, 0.07268715000600617, 0.6876997886650223, 0.17625257741529177, 0.12904206560762432, 0.006294734907688991, 0.9964860509545982, 0.25508561955326314, 0.10576720810745058, 0.17731561359190245, 0.015554001192272144, 0.13687521049199486, 0.304858423368534, 0.9987586695669569, 0.9981115418559624, 0.058902903998024586, 0.002454287666584358, 0.9381514605518707, 0.9903395692702515, 0.9965877569455183, 0.9889931234294149, 0.06329091818659498, 0.7645542916940674, 0.16961966074007453, 0.6560750587922612, 0.01595319291896076, 0.10967820131785523, 0.005982447344610285, 0.10768405220298513, 0.005982447344610285, 0.017947342033830856, 0.0797659645948038, 0.12706491145457738, 0.33577989909099343, 0.04444856218182935, 0.08261634927274802, 0.008696457818184003, 0.2140294896364174, 0.07633557418183735, 0.10145867454548003, 0.00917959436363867, 0.31848498128684505, 0.3810238503395346, 0.07875264991820169, 0.063696996257369, 0.055590105824612955, 0.08338515873691943, 0.018530035274870984, 0.9954299367218367, 0.9936166654736677, 0.9945890994142642, 0.9954290779944203, 0.9951791428569464, 0.118053107974482, 0.17204898974690133, 0.12643756166585146, 0.1787565526999969, 0.32665831581575416, 0.03454394920844218, 0.002347647033583449, 0.04091613401388297, 0.9911959970285755, 0.9900999283106977], \"Term\": [\"accid\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"address\", \"address\", \"address\", \"address\", \"address\", \"administr\", \"administr\", \"administr\", \"administr\", \"agenc\", \"agenc\", \"agenc\", \"agre\", \"agre\", \"agre\", \"agre\", \"aid\", \"alarm\", \"alcohol\", \"algorithm\", \"algorithm\", \"amend\", \"amiga\", \"amour\", \"annual\", \"annual\", \"annual\", \"annual\", \"anonym\", \"antibiot\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"applic\", \"applic\", \"applic\", \"applic\", \"april\", \"april\", \"april\", \"april\", \"april\", \"arab\", \"arab\", \"archiv\", \"archiv\", \"arena\", \"arg\", \"argic\", \"argument\", \"argv\", \"arm\", \"arm\", \"armenia\", \"armenian\", \"armi\", \"armi\", \"asid\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"attack\", \"attack\", \"attack\", \"aura\", \"austin\", \"automobil\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"aveng\", \"azerbaijan\", \"azerbaijani\", \"azeri\", \"bag\", \"baku\", \"balloon\", \"basebal\", \"bat\", \"batteri\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"belt\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bike\", \"biker\", \"bird\", \"bitmap\", \"bitnet\", \"bitnet\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"block\", \"block\", \"block\", \"blue\", \"blue\", \"blue\", \"blue\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"boston\", \"boston\", \"brake\", \"brand\", \"brand\", \"bruin\", \"buffalo\", \"burst\", \"burst\", \"button\", \"button\", \"button\", \"buy\", \"buy\", \"byte\", \"cadr\", \"cage\", \"calgari\", \"canadien\", \"cancer\", \"candida\", \"captain\", \"captain\", \"car\", \"card\", \"card\", \"card\", \"card\", \"card\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cassett\", \"caus\", \"caus\", \"caus\", \"caus\", \"caus\", \"cell\", \"cellular\", \"center\", \"center\", \"center\", \"center\", \"center\", \"certain\", \"certain\", \"certain\", \"certain\", \"certain\", \"certain\", \"channel\", \"channel\", \"channel\", \"channel\", \"chastiti\", \"chicago\", \"children\", \"children\", \"children\", \"chip\", \"chronic\", \"chuck\", \"cipher\", \"ciphertext\", \"circl\", \"circl\", \"claim\", \"claim\", \"claim\", \"claim\", \"classifi\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clemen\", \"click\", \"client\", \"client\", \"clinic\", \"clinton\", \"clinton\", \"clipper\", \"clipper\", \"cloud\", \"coach\", \"coat\", \"code\", \"code\", \"code\", \"color\", \"color\", \"color\", \"color\", \"color\", \"colormap\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comic\", \"communic\", \"communic\", \"communic\", \"communic\", \"compil\", \"compil\", \"comput\", \"comput\", \"comput\", \"condit\", \"condit\", \"condit\", \"condit\", \"condit\", \"condit\", \"configur\", \"configur\", \"configur\", \"consortium\", \"contrib\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"copi\", \"copi\", \"copi\", \"copi\", \"copi\", \"corvett\", \"counterst\", \"court\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"crypt\", \"cryptanalysi\", \"crypto\", \"cryptograph\", \"cryptographi\", \"cryptolog\", \"cursor\", \"data\", \"data\", \"data\", \"data\", \"dealer\", \"dealer\", \"decrypt\", \"default\", \"defens\", \"defens\", \"defens\", \"defens\", \"defens\", \"defin\", \"defin\", \"defin\", \"deliveri\", \"den\", \"depress\", \"detector\", \"detroit\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"devic\", \"devic\", \"devic\", \"devil\", \"diet\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"diseas\", \"disk\", \"disk\", \"disk\", \"display\", \"distanc\", \"distanc\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"dive\", \"divis\", \"divis\", \"divis\", \"donat\", \"door\", \"door\", \"door\", \"dorothi\", \"drive\", \"drive\", \"drive\", \"drug\", \"drug\", \"earth\", \"earth\", \"eat\", \"echo\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"email\", \"email\", \"email\", \"encrypt\", \"enforc\", \"enforc\", \"enforc\", \"engin\", \"engin\", \"engin\", \"ensur\", \"entri\", \"error\", \"error\", \"error\", \"error\", \"erzurum\", \"escrow\", \"espn\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"evid\", \"evid\", \"evid\", \"evid\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"exit\", \"export\", \"export\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fan\", \"file\", \"file\", \"file\", \"file\", \"filenam\", \"flash\", \"flash\", \"floppi\", \"floppi\", \"flyer\", \"flyer\", \"font\", \"footbal\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"ford\", \"forsal\", \"found\", \"function\", \"function\", \"function\", \"function\", \"function\", \"galaxi\", \"game\", \"game\", \"gamma\", \"gamma\", \"gant\", \"garag\", \"gaza\", \"gear\", \"gear\", \"genesi\", \"genocid\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goali\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"govern\", \"govern\", \"graphic\", \"graphic\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greec\", \"greek\", \"green\", \"green\", \"green\", \"green\", \"green\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"hacker\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"harley\", \"hawk\", \"hawk\", \"health\", \"health\", \"heard\", \"heard\", \"heard\", \"heard\", \"hellman\", \"helmet\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"histori\", \"histori\", \"histori\", \"histori\", \"histori\", \"hitter\", \"hockey\", \"hole\", \"hole\", \"hole\", \"hole\", \"honda\", \"hulk\", \"icon\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"ignor\", \"ignor\", \"ignor\", \"ignor\", \"imak\", \"immun\", \"impli\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"incred\", \"incred\", \"incred\", \"infect\", \"infecti\", \"info\", \"info\", \"info\", \"info\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inning\", \"insur\", \"insur\", \"intellect\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"interfac\", \"interfac\", \"internet\", \"intestin\", \"invent\", \"islam\", \"islam\", \"isra\", \"israel\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"istanbul\", \"itali\", \"item\", \"item\", \"item\", \"item\", \"item\", \"jerusalem\", \"jew\", \"jew\", \"jewish\", \"jewish\", \"jose\", \"key\", \"key\", \"keyword\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"king\", \"king\", \"king\", \"king\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"laptop\", \"launch\", \"leaf\", \"leagu\", \"leagu\", \"lean\", \"lebanes\", \"lebanon\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"legal\", \"legal\", \"legal\", \"lesson\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"linux\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"listserv\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"live\", \"live\", \"live\", \"live\", \"lock\", \"lock\", \"lock\", \"login\", \"london\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lost\", \"lost\", \"lost\", \"lost\", \"lost\", \"lost\", \"loui\", \"lunar\", \"macintosh\", \"mail\", \"mail\", \"mail\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"makefil\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manag\", \"manual\", \"manual\", \"manual\", \"manual\", \"mar\", \"marvel\", \"mask\", \"mask\", \"massacr\", \"massacr\", \"mathemat\", \"mayb\", \"mayb\", \"mayb\", \"mayb\", \"mayb\", \"mazda\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"medic\", \"medic\", \"medicin\", \"menu\", \"messag\", \"messag\", \"messag\", \"microsoft\", \"mile\", \"mile\", \"mile\", \"mile\", \"miner\", \"mini\", \"minnesota\", \"mint\", \"mission\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modem\", \"modem\", \"montreal\", \"moon\", \"moon\", \"morri\", \"motif\", \"motorcycl\", \"motorcycl\", \"mous\", \"mous\", \"murder\", \"music\", \"music\", \"muslim\", \"mustang\", \"mutant\", \"nasa\", \"nasa\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nazi\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"neighbor\", \"netcom\", \"network\", \"network\", \"network\", \"network\", \"network\", \"news\", \"news\", \"news\", \"news\", \"news\", \"newsgroup\", \"newsgroup\", \"newslett\", \"ninja\", \"nois\", \"null\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"olwm\", \"oort\", \"openwindow\", \"opinion\", \"opinion\", \"opinion\", \"orbit\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"ottoman\", \"output\", \"output\", \"packag\", \"packag\", \"packag\", \"palestinian\", \"palestinian\", \"pars\", \"passeng\", \"passeng\", \"patch\", \"patch\", \"patent\", \"patient\", \"pen\", \"penalti\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"philadelphia\", \"phone\", \"phone\", \"phone\", \"phone\", \"photographi\", \"phrase\", \"physician\", \"pitch\", \"pitcher\", \"pittsburgh\", \"pixel\", \"pixmap\", \"plaintext\", \"planet\", \"planet\", \"plastic\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"playoff\", \"playoff\", \"plus\", \"plus\", \"plus\", \"plus\", \"plus\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pointer\", \"pop\", \"popul\", \"popul\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"preview\", \"price\", \"price\", \"price\", \"price\", \"print\", \"print\", \"print\", \"print\", \"printer\", \"printf\", \"prison\", \"privaci\", \"privat\", \"privat\", \"privat\", \"privat\", \"probe\", \"probe\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"processor\", \"prog\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"propos\", \"propos\", \"propos\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protein\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"public\", \"public\", \"public\", \"public\", \"public\", \"puck\", \"purchas\", \"purchas\", \"purchas\", \"purchas\", \"quack\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"ranger\", \"ranger\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"readm\", \"realiti\", \"realiti\", \"rear\", \"rear\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"recipi\", \"refere\", \"rememb\", \"rememb\", \"rememb\", \"rememb\", \"rememb\", \"replay\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"request\", \"request\", \"request\", \"request\", \"request\", \"research\", \"research\", \"research\", \"research\", \"research\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"resourc\", \"reveal\", \"ride\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"ripem\", \"rocket\", \"rocket\", \"rocket\", \"rocket\", \"run\", \"run\", \"run\", \"run\", \"run\", \"russian\", \"russian\", \"russian\", \"sabr\", \"said\", \"said\", \"said\", \"said\", \"said\", \"sale\", \"satellit\", \"saturn\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scheme\", \"scienc\", \"scienc\", \"scienc\", \"score\", \"screen\", \"screen\", \"screen\", \"screen\", \"scsi\", \"scsi\", \"season\", \"seat\", \"seat\", \"seat\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"secret\", \"secret\", \"secret\", \"section\", \"section\", \"section\", \"section\", \"section\", \"secur\", \"secur\", \"sell\", \"sell\", \"sell\", \"sell\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"serdar\", \"seri\", \"seri\", \"seri\", \"seri\", \"seri\", \"seri\", \"server\", \"server\", \"shark\", \"ship\", \"ship\", \"shit\", \"shot\", \"shot\", \"shout\", \"shutout\", \"shuttl\", \"sigh\", \"silicon\", \"silver\", \"site\", \"site\", \"site\", \"situat\", \"situat\", \"situat\", \"situat\", \"slash\", \"slash\", \"smooth\", \"softwar\", \"softwar\", \"softwar\", \"softwar\", \"softwar\", \"soldier\", \"sourc\", \"sourc\", \"sourc\", \"sourc\", \"sourc\", \"soviet\", \"soviet\", \"space\", \"space\", \"space\", \"space\", \"spacecraft\", \"sparc\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"spider\", \"stadium\", \"stadium\", \"star\", \"star\", \"star\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"stat\", \"stat\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"steer\", \"stereo\", \"stream\", \"stream\", \"string\", \"studi\", \"studi\", \"studi\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subscrib\", \"subscript\", \"sumgait\", \"suno\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"surveil\", \"suspens\", \"sweden\", \"switzerland\", \"symptom\", \"syndrom\", \"tail\", \"tail\", \"tail\", \"tape\", \"tape\", \"tape\", \"tartar\", \"team\", \"team\", \"technolog\", \"technolog\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"temperatur\", \"terror\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"theoret\", \"therapi\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"throttl\", \"ticket\", \"ticket\", \"ticket\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"told\", \"told\", \"tommi\", \"toolkit\", \"toronto\", \"toronto\", \"torqu\", \"toyota\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"treatment\", \"treatment\", \"trek\", \"troop\", \"true\", \"true\", \"true\", \"true\", \"true\", \"trust\", \"trust\", \"trust\", \"tune\", \"turbo\", \"turbo\", \"turk\", \"turkey\", \"turkish\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"tutori\", \"univers\", \"univers\", \"univers\", \"univers\", \"usenet\", \"usenet\", \"user\", \"user\", \"user\", \"uucp\", \"uuencod\", \"vaccin\", \"valv\", \"version\", \"version\", \"version\", \"version\", \"villag\", \"vitamin\", \"void\", \"vote\", \"wagon\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"went\", \"went\", \"went\", \"went\", \"wheel\", \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"widget\", \"win\", \"window\", \"window\", \"window\", \"winnipeg\", \"wiretap\", \"wolverin\", \"women\", \"women\", \"women\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"wound\", \"xfree\", \"xlib\", \"xterm\", \"xview\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yeast\", \"zionist\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 8, 5, 4, 9, 7, 3, 1, 6, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el6781384881889116801062507508\", ldavis_el6781384881889116801062507508_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el6781384881889116801062507508\", ldavis_el6781384881889116801062507508_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el6781384881889116801062507508\", ldavis_el6781384881889116801062507508_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "import pyLDAvis.gensim\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
        "vis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wpQENG7Dsl"
      },
      "source": [
        "Note, for newer versions of `gensim`, use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CEqWz0y7Dsl"
      },
      "outputs": [],
      "source": [
        "#import pyLDAvis.gensim_models\n",
        "#pyLDAvis.enable_notebook()\n",
        "#vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
        "#vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCDWw_ae7Dsl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}